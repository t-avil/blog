<!doctype html><html lang=en dir=auto><head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>FAST_GUIDE: How to Build Your Own Version of NumPy | T|A</title><meta name=keywords content="cuda,python,numpy,pybind,cpp,SIMD,CUDA,OpenMP,scientific computing,extensions,packaging,abi"><meta name=description content="From minimal pybind11 demos to vectorized CPU routines and CUDA acceleration learn to build Python C++ extensions and understand so files wheel distribution and Python ABI."><meta name=author content="Me"><link rel=canonical href=https://canonical.url/to/page><link crossorigin=anonymous href=/assets/css/stylesheet.3f7ba6a00d316a1658af1e52b60f5592bfd3f63e1683217d447958625c9fec2a.css integrity="sha256-P3umoA0xahZYrx5Stg9Vkr/T9j4WgyF9RHlYYlyf7Co=" rel="preload stylesheet" as=style><link rel=icon href=http://localhost:1313/favicon.ico><link rel=icon type=image/png sizes=16x16 href=http://localhost:1313/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=http://localhost:1313/favicon-32x32.png><link rel=apple-touch-icon href=http://localhost:1313/apple-touch-icon.png><link rel=mask-icon href=http://localhost:1313/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=http://localhost:1313/posts/pybind/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:url" content="http://localhost:1313/posts/pybind/"><meta property="og:site_name" content="T|A"><meta property="og:title" content="FAST_GUIDE: How to Build Your Own Version of NumPy"><meta property="og:description" content="From minimal pybind11 demos to vectorized CPU routines and CUDA acceleration learn to build Python C++ extensions and understand so files wheel distribution and Python ABI."><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2026-01-21T23:27:20-08:00"><meta property="article:modified_time" content="2026-01-21T23:27:20-08:00"><meta property="article:tag" content="Python"><meta property="article:tag" content="Numpy"><meta property="article:tag" content="Pybind"><meta property="article:tag" content="Cpp"><meta property="article:tag" content="SIMD"><meta property="article:tag" content="CUDA"><meta property="og:image" content="http://localhost:1313/images/papermod-cover.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="http://localhost:1313/images/papermod-cover.png"><meta name=twitter:title content="FAST_GUIDE: How to Build Your Own Version of NumPy"><meta name=twitter:description content="From minimal pybind11 demos to vectorized CPU routines and CUDA acceleration learn to build Python C++ extensions and understand so files wheel distribution and Python ABI."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"http://localhost:1313/posts/"},{"@type":"ListItem","position":2,"name":"FAST_GUIDE: How to Build Your Own Version of NumPy","item":"http://localhost:1313/posts/pybind/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"FAST_GUIDE: How to Build Your Own Version of NumPy","name":"FAST_GUIDE: How to Build Your Own Version of NumPy","description":"From minimal pybind11 demos to vectorized CPU routines and CUDA acceleration learn to build Python C++ extensions and understand so files wheel distribution and Python ABI.","keywords":["cuda","python","numpy","pybind","cpp","SIMD","CUDA","OpenMP","scientific computing","extensions","packaging","abi"],"articleBody":"Python is expressive and flexible but slow for heavy numeric computation. Libraries like NumPy exist because someone realized Python is great for expressing ideas but too slow for matrix multiplications or numerical loops. Pybind11 allows us to write C++ code, expose it to Python, and package it in a cross-platform way.\nIn this post we will go from environment setup, to writing three pybind11 functions (simple add, vectorized CPU, GPU CUDA), to deep understanding of .so files, Python packaging, wheels, and ABI compatibility, showing how everything connects under the hood.\n1 Environment setup On Rocky Linux install required tools\nsudo dnf install -y python3 python3-devel gcc gcc-c++ make cmake pip3 install --user pybind11 wheel setuptools numpy Check Python and compiler\npython3 --version gcc --version python3 -m pybind11 --includes 2 Project structure We will build three functions:\nadd_simple minimal integer addition add_vectorized optimized with SIMD, OpenMP, and BLAS add_cuda GPU accelerated Directory layout:\npybind_demo setup.py example.cpp example_cuda.cu __init__.py 3 Simple addition function example.cpp\n#include namespace py = pybind11 int add_simple(int a int b) { return a + b } PYBIND11_MODULE(example m) { m.def(\"add_simple\" \u0026add_simple \"Add two integers\") } Build and test\npython3 setup.py build_ext --inplace python3 \u003e\u003e\u003e import example \u003e\u003e\u003e example.add_simple(2 3) 5 This produces a .so shared object that Python dynamically loads.\n4 Vectorized CPU function High performance numeric code relies on SIMD (single instruction multiple data), multi-core parallelism (OpenMP), and tuned linear algebra libraries (BLAS/LAPACK).\nSIMD Modern CPUs have vector registers AVX2, AVX-512, or NEON. Operations like addition, multiplication, or dot product can process multiple elements at once. You can use intrinsics or rely on compiler auto-vectorization. Example using AVX2:\n#include void add_float_avx(float* a float* b float* out int n) { for (int i = 0 i \u003c n i += 8) { __m256 va = _mm256_loadu_ps(a + i) __m256 vb = _mm256_loadu_ps(b + i) __m256 vc = _mm256_add_ps(va vb) _mm256_storeu_ps(out + i vc) } } OpenMP Parallelize loops across CPU cores:\n#pragma omp parallel for for (int i = 0 i \u003c N i++) { out[i] = a[i] + b[i] } BLAS/LAPACK For linear algebra rely on optimized libraries like OpenBLAS or MKL. Pybind11 can expose these routines to Python. Example: cblas_sgemm for matrix multiplication.\nFull Pybind example #include #include #include #ifdef _OPENMP #include #endif namespace py = pybind11 py::array_t\u003cfloat\u003e add_vectorized(py::array_t\u003cfloat\u003e a py::array_t\u003cfloat\u003e b) { auto buf_a = a.request() auto buf_b = b.request() if(buf_a.size != buf_b.size) throw std::runtime_error(\"Arrays must be same size\") auto result = py::array_t\u003cfloat\u003e(buf_a.size) auto buf_r = result.request() float* ptr_a = (float*)buf_a.ptr float* ptr_b = (float*)buf_b.ptr float* ptr_r = (float*)buf_r.ptr size_t n = buf_a.size #pragma omp parallel for for(size_t i = 0 i \u003c n i += 8) { __m256 va = _mm256_loadu_ps(ptr_a + i) __m256 vb = _mm256_loadu_ps(ptr_b + i) __m256 vr = _mm256_add_ps(va vb) _mm256_storeu_ps(ptr_r + i vr) } return result } PYBIND11_MODULE(example m) { m.def(\"add_vectorized\" \u0026add_vectorized \"Vectorized float addition with SIMD and OpenMP\") } 5 CUDA GPU function example_cuda.cu\n#include #include #include namespace py = pybind11 __global__ void add_kernel(float* a float* b float* out int n) { int idx = threadIdx.x + blockIdx.x * blockDim.x if(idx \u003c n) out[idx] = a[idx] + b[idx] } py::array_t\u003cfloat\u003e add_cuda(py::array_t\u003cfloat\u003e a py::array_t\u003cfloat\u003e b) { auto buf_a = a.request() auto buf_b = b.request() if(buf_a.size != buf_b.size) throw std::runtime_error(\"Arrays must be same size\") int n = buf_a.size float *d_a *d_b *d_out cudaMalloc(\u0026d_a n*sizeof(float)) cudaMalloc(\u0026d_b n*sizeof(float)) cudaMalloc(\u0026d_out n*sizeof(float)) cudaMemcpy(d_a buf_a.ptr n*sizeof(float) cudaMemcpyHostToDevice) cudaMemcpy(d_b buf_b.ptr n*sizeof(float) cudaMemcpyHostToDevice) int block = 256 grid = (n + block - 1)/block add_kernel\u003c\u003c\u003cgrid block\u003e\u003e\u003e(d_a d_b d_out n) auto result = py::array_t\u003cfloat\u003e(n) cudaMemcpy(result.mutable_data() d_out n*sizeof(float) cudaMemcpyDeviceToHost) cudaFree(d_a) cudaFree(d_b) cudaFree(d_out) return result } PYBIND11_MODULE(example m) { m.def(\"add_cuda\" \u0026add_cuda \"Add arrays on GPU with CUDA\") } Compile with:\nnvcc --compiler-options '-fPIC' -O3 -shared example_cuda.cu -o example_cuda.so -lcudart Python sees the .so as a normal module while execution happens on GPU\n6 Understanding .so files, wheels, and Python ABI Python ABI means Application Binary Interface. The chain is:\nPython → CPython ABI → .so → C++ functions Pybind11 leverages this chain. Using setuptools we can compile C++ code into a .so file that Python can load dynamically. A .so file is not a standalone program it is a live binary module:\n.exe standalone executable .a static library (copied in at compile time) .so shared library loaded at runtime Alternatives:\nLinux .so macOS .dylib Windows .dll Anatomy of a .so file A .so is an ELF file containing:\nMachine code - CPU instructions not bytecode\nSymbol table - exported functions and variables for linking\nRelocation info - how addresses are fixed at load time\nDynamic section - dependencies on other .so files\nSections:\n.text executable code .data initialized globals .bss uninitialized globals .rodata constants Runtime usage Program starts Dynamic linker (ld-linux.so) loads .so Symbols resolved Code mapped into memory Functions callable like normal code Important note: .so files cannot be moved across CPU architectures\nWheels Wheels (.whl) are Python distribution packages that can include .so modules. They allow precompiled code to be installed with pip, avoiding the need for users to have a compiler:\npython setup.py bdist_wheel pip install dist/example-0.1.0-cp311-cp311-linux_x86_64.whl Key difference: .so is the runtime artifact. Wheel is the distribution format containing .so files, metadata, and Python package structure.\n7 Setup script setup.py\nfrom setuptools import setup, Extension import pybind11 import os import sys from setuptools.command.build_ext import build_ext import subprocess # Custom class to compile CUDA with nvcc class BuildExtWithCUDA(build_ext): def build_extensions(self): for ext in self.extensions: if getattr(ext, 'cuda', False): self.build_cuda_extension(ext) else: super().build_extensions() def build_cuda_extension(self, ext): # Build the CUDA .cu file into a shared library output_dir = os.path.abspath(self.build_lib) lib_file = os.path.join(output_dir, ext.name + \".so\") os.makedirs(output_dir, exist_ok=True) cmd = [ \"nvcc\", \"-O3\", \"--compiler-options\", \"'-fPIC'\", \"-shared\", *ext.sources, \"-o\", lib_file, \"-Xcompiler\", \"-fPIC\" ] print(\"Building CUDA extension:\", \" \".join(cmd)) subprocess.check_call(\" \".join(cmd), shell=True) # CPU vectorized extension cpu_ext = Extension( \"example\", [\"example.cpp\"], include_dirs=[pybind11.get_include()], extra_compile_args=[\"-O3\", \"-march=native\", \"-fopenmp\"], language=\"c++\" ) # CUDA extension cuda_ext = Extension( \"example_cuda\", [\"example_cuda.cu\"], include_dirs=[pybind11.get_include()], ) cuda_ext.cuda = True # mark it as CUDA setup( name=\"example\", ext_modules=[cpu_ext, cuda_ext], cmdclass={\"build_ext\": BuildExtWithCUDA}, zip_safe=False, ) 8 Demo and Benchmark import example import numpy as np import time # Simple sanity check print(\"Simple addition:\", example.add_simple(1, 2)) # Prepare large arrays for benchmarking N = 10_000_000 a = np.random.rand(N).astype(np.float32) b = np.random.rand(N).astype(np.float32) # Vectorized CPU addition start_cpu = time.time() c_cpu = example.add_vectorized(a, b) end_cpu = time.time() print(f\"CPU vectorized addition first 10 elements: {c_cpu[:10]}\") print(f\"CPU vectorized addition time: {end_cpu - start_cpu:.6f} seconds\") # CUDA GPU addition start_gpu = time.time() c_gpu = example.add_cuda(a, b) end_gpu = time.time() print(f\"GPU CUDA addition first 10 elements: {c_gpu[:10]}\") print(f\"GPU CUDA addition time: {end_gpu - start_gpu:.6f} seconds\") # Verify correctness if np.allclose(c_cpu, c_gpu): print(\"CPU and GPU results match!\") else: print(\"Warning: CPU and GPU results do not match!\") ","wordCount":"1113","inLanguage":"en","image":"http://localhost:1313/images/papermod-cover.png","datePublished":"2026-01-21T23:27:20-08:00","dateModified":"2026-01-21T23:27:20-08:00","author":{"@type":"Person","name":"Me"},"mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:1313/posts/pybind/"},"publisher":{"@type":"Organization","name":"T|A","logo":{"@type":"ImageObject","url":"http://localhost:1313/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=http://localhost:1313/ accesskey=h title="T|A (Alt + H)">T|A</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=http://localhost:1313/about title=About><span>About</span></a></li><li><a href=http://localhost:1313/chronicles title=Chronicles><span>Chronicles</span></a></li><li><a href=http://localhost:1313/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=http://localhost:1313/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://github.com/t-avil title=Github><span>Github</span>&nbsp;
<svg fill="none" shape-rendering="geometricPrecision" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=http://localhost:1313/>Home</a>&nbsp;»&nbsp;<a href=http://localhost:1313/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">FAST_GUIDE: How to Build Your Own Version of NumPy</h1><div class=post-description>From minimal pybind11 demos to vectorized CPU routines and CUDA acceleration learn to build Python C++ extensions and understand so files wheel distribution and Python ABI.</div><div class=post-meta><span title='2026-01-21 23:27:20 -0800 PST'>January 21, 2026</span>&nbsp;·&nbsp;6 min&nbsp;·&nbsp;1113 words&nbsp;·&nbsp;Me&nbsp;|&nbsp;<a href=https://github.com/t-avil/blog/tree/main/content/posts/pybind.md rel="noopener noreferrer edit" target=_blank>Suggest Changes</a></div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><nav id=TableOfContents><ul><li><a href=#1-environment-setup>1 Environment setup</a></li><li><a href=#2-project-structure>2 Project structure</a></li><li><a href=#3-simple-addition-function>3 Simple addition function</a></li><li><a href=#4-vectorized-cpu-function>4 Vectorized CPU function</a><ul><li><a href=#simd>SIMD</a></li><li><a href=#openmp>OpenMP</a></li><li><a href=#blaslapack>BLAS/LAPACK</a></li><li><a href=#full-pybind-example>Full Pybind example</a></li></ul></li><li><a href=#5-cuda-gpu-function>5 CUDA GPU function</a></li><li><a href=#6-understanding-so-files-wheels-and-python-abi>6 Understanding .so files, wheels, and Python ABI</a><ul><li><a href=#anatomy-of-a-so-file>Anatomy of a <code>.so</code> file</a></li><li><a href=#runtime-usage>Runtime usage</a></li><li><a href=#wheels>Wheels</a></li></ul></li><li><a href=#7-setup-script>7 Setup script</a></li><li><a href=#8-demo-and-benchmark>8 Demo and Benchmark</a></li></ul></nav></div></details></div><div class=post-content><p>Python is expressive and flexible but slow for heavy numeric computation. Libraries like NumPy exist because someone realized Python is great for expressing ideas but too slow for matrix multiplications or numerical loops. Pybind11 allows us to write <strong>C++ code, expose it to Python, and package it in a cross-platform way</strong>.</p><p>In this post we will go from <strong>environment setup</strong>, to <strong>writing three pybind11 functions</strong> (simple add, vectorized CPU, GPU CUDA), to <strong>deep understanding of .so files, Python packaging, wheels, and ABI compatibility</strong>, showing how everything connects under the hood.</p><hr><h2 id=1-environment-setup>1 Environment setup<a hidden class=anchor aria-hidden=true href=#1-environment-setup>#</a></h2><p>On Rocky Linux install required tools</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>sudo dnf install -y python3 python3-devel gcc gcc-c++ make cmake
</span></span><span class=line><span class=cl>pip3 install --user pybind11 wheel setuptools numpy
</span></span></code></pre></div><p>Check Python and compiler</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>python3 --version
</span></span><span class=line><span class=cl>gcc --version
</span></span><span class=line><span class=cl>python3 -m pybind11 --includes
</span></span></code></pre></div><hr><h2 id=2-project-structure>2 Project structure<a hidden class=anchor aria-hidden=true href=#2-project-structure>#</a></h2><p>We will build three functions:</p><ul><li><code>add_simple</code> minimal integer addition</li><li><code>add_vectorized</code> optimized with SIMD, OpenMP, and BLAS</li><li><code>add_cuda</code> GPU accelerated</li></ul><p>Directory layout:</p><pre tabindex=0><code>pybind_demo
setup.py
example.cpp
example_cuda.cu
__init__.py
</code></pre><hr><h2 id=3-simple-addition-function>3 Simple addition function<a hidden class=anchor aria-hidden=true href=#3-simple-addition-function>#</a></h2><p>example.cpp</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-cpp data-lang=cpp><span class=line><span class=cl><span class=cp>#include</span> <span class=cpf>&lt;pybind11/pybind11.h&gt;</span><span class=cp>
</span></span></span><span class=line><span class=cl><span class=cp></span><span class=k>namespace</span> <span class=n>py</span> <span class=o>=</span> <span class=n>pybind11</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kt>int</span> <span class=n>add_simple</span><span class=p>(</span><span class=kt>int</span> <span class=n>a</span> <span class=kt>int</span> <span class=n>b</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>a</span> <span class=o>+</span> <span class=n>b</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>PYBIND11_MODULE</span><span class=p>(</span><span class=n>example</span> <span class=n>m</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=n>m</span><span class=p>.</span><span class=n>def</span><span class=p>(</span><span class=s>&#34;add_simple&#34;</span> <span class=o>&amp;</span><span class=n>add_simple</span> <span class=s>&#34;Add two integers&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>Build and test</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>python3 setup.py build_ext --inplace
</span></span><span class=line><span class=cl>python3
</span></span><span class=line><span class=cl>&gt;&gt;&gt; import example
</span></span><span class=line><span class=cl>&gt;&gt;&gt; example.add_simple<span class=o>(</span><span class=m>2</span> 3<span class=o>)</span>
</span></span><span class=line><span class=cl><span class=m>5</span>
</span></span></code></pre></div><p>This produces a <code>.so</code> shared object that Python dynamically loads.</p><hr><h2 id=4-vectorized-cpu-function>4 Vectorized CPU function<a hidden class=anchor aria-hidden=true href=#4-vectorized-cpu-function>#</a></h2><p>High performance numeric code relies on <strong>SIMD</strong> (single instruction multiple data), <strong>multi-core parallelism</strong> (OpenMP), and <strong>tuned linear algebra libraries</strong> (BLAS/LAPACK).</p><h3 id=simd>SIMD<a hidden class=anchor aria-hidden=true href=#simd>#</a></h3><p>Modern CPUs have vector registers AVX2, AVX-512, or NEON. Operations like addition, multiplication, or dot product can process multiple elements at once. You can use intrinsics or rely on compiler auto-vectorization. Example using AVX2:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-cpp data-lang=cpp><span class=line><span class=cl><span class=cp>#include</span> <span class=cpf>&lt;immintrin.h&gt;</span><span class=cp>
</span></span></span><span class=line><span class=cl><span class=cp></span>
</span></span><span class=line><span class=cl><span class=kt>void</span> <span class=nf>add_float_avx</span><span class=p>(</span><span class=kt>float</span><span class=o>*</span> <span class=n>a</span> <span class=kt>float</span><span class=o>*</span> <span class=n>b</span> <span class=kt>float</span><span class=o>*</span> <span class=n>out</span> <span class=kt>int</span> <span class=n>n</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=p>(</span><span class=kt>int</span> <span class=n>i</span> <span class=o>=</span> <span class=mi>0</span> <span class=n>i</span> <span class=o>&lt;</span> <span class=n>n</span> <span class=n>i</span> <span class=o>+=</span> <span class=mi>8</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=n>__m256</span> <span class=n>va</span> <span class=o>=</span> <span class=n>_mm256_loadu_ps</span><span class=p>(</span><span class=n>a</span> <span class=o>+</span> <span class=n>i</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>__m256</span> <span class=n>vb</span> <span class=o>=</span> <span class=n>_mm256_loadu_ps</span><span class=p>(</span><span class=n>b</span> <span class=o>+</span> <span class=n>i</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>__m256</span> <span class=n>vc</span> <span class=o>=</span> <span class=n>_mm256_add_ps</span><span class=p>(</span><span class=n>va</span> <span class=n>vb</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>_mm256_storeu_ps</span><span class=p>(</span><span class=n>out</span> <span class=o>+</span> <span class=n>i</span> <span class=n>vc</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><h3 id=openmp>OpenMP<a hidden class=anchor aria-hidden=true href=#openmp>#</a></h3><p>Parallelize loops across CPU cores:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-cpp data-lang=cpp><span class=line><span class=cl><span class=cp>#pragma omp parallel for
</span></span></span><span class=line><span class=cl><span class=cp></span><span class=k>for</span> <span class=p>(</span><span class=kt>int</span> <span class=n>i</span> <span class=o>=</span> <span class=mi>0</span> <span class=n>i</span> <span class=o>&lt;</span> <span class=n>N</span> <span class=n>i</span><span class=o>++</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=n>out</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=o>=</span> <span class=n>a</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=o>+</span> <span class=n>b</span><span class=p>[</span><span class=n>i</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><h3 id=blaslapack>BLAS/LAPACK<a hidden class=anchor aria-hidden=true href=#blaslapack>#</a></h3><p>For linear algebra rely on optimized libraries like OpenBLAS or MKL. Pybind11 can expose these routines to Python. Example: <code>cblas_sgemm</code> for matrix multiplication.</p><h3 id=full-pybind-example>Full Pybind example<a hidden class=anchor aria-hidden=true href=#full-pybind-example>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-cpp data-lang=cpp><span class=line><span class=cl><span class=cp>#include</span> <span class=cpf>&lt;pybind11/pybind11.h&gt;</span><span class=cp>
</span></span></span><span class=line><span class=cl><span class=cp>#include</span> <span class=cpf>&lt;pybind11/numpy.h&gt;</span><span class=cp>
</span></span></span><span class=line><span class=cl><span class=cp>#include</span> <span class=cpf>&lt;immintrin.h&gt;</span><span class=cp>
</span></span></span><span class=line><span class=cl><span class=cp>#ifdef _OPENMP
</span></span></span><span class=line><span class=cl><span class=cp>#include</span> <span class=cpf>&lt;omp.h&gt;</span><span class=cp>
</span></span></span><span class=line><span class=cl><span class=cp>#endif
</span></span></span><span class=line><span class=cl><span class=cp></span><span class=k>namespace</span> <span class=n>py</span> <span class=o>=</span> <span class=n>pybind11</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>py</span><span class=o>::</span><span class=n>array_t</span><span class=o>&lt;</span><span class=kt>float</span><span class=o>&gt;</span> <span class=n>add_vectorized</span><span class=p>(</span><span class=n>py</span><span class=o>::</span><span class=n>array_t</span><span class=o>&lt;</span><span class=kt>float</span><span class=o>&gt;</span> <span class=n>a</span> <span class=n>py</span><span class=o>::</span><span class=n>array_t</span><span class=o>&lt;</span><span class=kt>float</span><span class=o>&gt;</span> <span class=n>b</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=k>auto</span> <span class=n>buf_a</span> <span class=o>=</span> <span class=n>a</span><span class=p>.</span><span class=n>request</span><span class=p>()</span> 
</span></span><span class=line><span class=cl>    <span class=k>auto</span> <span class=n>buf_b</span> <span class=o>=</span> <span class=n>b</span><span class=p>.</span><span class=n>request</span><span class=p>()</span> 
</span></span><span class=line><span class=cl>    <span class=k>if</span><span class=p>(</span><span class=n>buf_a</span><span class=p>.</span><span class=n>size</span> <span class=o>!=</span> <span class=n>buf_b</span><span class=p>.</span><span class=n>size</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>throw</span> <span class=n>std</span><span class=o>::</span><span class=n>runtime_error</span><span class=p>(</span><span class=s>&#34;Arrays must be same size&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>auto</span> <span class=n>result</span> <span class=o>=</span> <span class=n>py</span><span class=o>::</span><span class=n>array_t</span><span class=o>&lt;</span><span class=kt>float</span><span class=o>&gt;</span><span class=p>(</span><span class=n>buf_a</span><span class=p>.</span><span class=n>size</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>auto</span> <span class=n>buf_r</span> <span class=o>=</span> <span class=n>result</span><span class=p>.</span><span class=n>request</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=kt>float</span><span class=o>*</span> <span class=n>ptr_a</span> <span class=o>=</span> <span class=p>(</span><span class=kt>float</span><span class=o>*</span><span class=p>)</span><span class=n>buf_a</span><span class=p>.</span><span class=n>ptr</span>
</span></span><span class=line><span class=cl>    <span class=kt>float</span><span class=o>*</span> <span class=n>ptr_b</span> <span class=o>=</span> <span class=p>(</span><span class=kt>float</span><span class=o>*</span><span class=p>)</span><span class=n>buf_b</span><span class=p>.</span><span class=n>ptr</span>
</span></span><span class=line><span class=cl>    <span class=kt>float</span><span class=o>*</span> <span class=n>ptr_r</span> <span class=o>=</span> <span class=p>(</span><span class=kt>float</span><span class=o>*</span><span class=p>)</span><span class=n>buf_r</span><span class=p>.</span><span class=n>ptr</span>
</span></span><span class=line><span class=cl>    <span class=n>size_t</span> <span class=n>n</span> <span class=o>=</span> <span class=n>buf_a</span><span class=p>.</span><span class=n>size</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=cp>#pragma omp parallel for
</span></span></span><span class=line><span class=cl><span class=cp></span>    <span class=k>for</span><span class=p>(</span><span class=n>size_t</span> <span class=n>i</span> <span class=o>=</span> <span class=mi>0</span> <span class=n>i</span> <span class=o>&lt;</span> <span class=n>n</span> <span class=n>i</span> <span class=o>+=</span> <span class=mi>8</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=n>__m256</span> <span class=n>va</span> <span class=o>=</span> <span class=n>_mm256_loadu_ps</span><span class=p>(</span><span class=n>ptr_a</span> <span class=o>+</span> <span class=n>i</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>__m256</span> <span class=n>vb</span> <span class=o>=</span> <span class=n>_mm256_loadu_ps</span><span class=p>(</span><span class=n>ptr_b</span> <span class=o>+</span> <span class=n>i</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>__m256</span> <span class=n>vr</span> <span class=o>=</span> <span class=n>_mm256_add_ps</span><span class=p>(</span><span class=n>va</span> <span class=n>vb</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>_mm256_storeu_ps</span><span class=p>(</span><span class=n>ptr_r</span> <span class=o>+</span> <span class=n>i</span> <span class=n>vr</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>result</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>PYBIND11_MODULE</span><span class=p>(</span><span class=n>example</span> <span class=n>m</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=n>m</span><span class=p>.</span><span class=n>def</span><span class=p>(</span><span class=s>&#34;add_vectorized&#34;</span> <span class=o>&amp;</span><span class=n>add_vectorized</span> <span class=s>&#34;Vectorized float addition with SIMD and OpenMP&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><hr><h2 id=5-cuda-gpu-function>5 CUDA GPU function<a hidden class=anchor aria-hidden=true href=#5-cuda-gpu-function>#</a></h2><p>example_cuda.cu</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-cpp data-lang=cpp><span class=line><span class=cl><span class=cp>#include</span> <span class=cpf>&lt;pybind11/pybind11.h&gt;</span><span class=cp>
</span></span></span><span class=line><span class=cl><span class=cp>#include</span> <span class=cpf>&lt;pybind11/numpy.h&gt;</span><span class=cp>
</span></span></span><span class=line><span class=cl><span class=cp>#include</span> <span class=cpf>&lt;cuda_runtime.h&gt;</span><span class=cp>
</span></span></span><span class=line><span class=cl><span class=cp></span><span class=k>namespace</span> <span class=n>py</span> <span class=o>=</span> <span class=n>pybind11</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>__global__</span> <span class=kt>void</span> <span class=n>add_kernel</span><span class=p>(</span><span class=kt>float</span><span class=o>*</span> <span class=n>a</span> <span class=kt>float</span><span class=o>*</span> <span class=n>b</span> <span class=kt>float</span><span class=o>*</span> <span class=n>out</span> <span class=kt>int</span> <span class=n>n</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=kt>int</span> <span class=n>idx</span> <span class=o>=</span> <span class=n>threadIdx</span><span class=p>.</span><span class=n>x</span> <span class=o>+</span> <span class=n>blockIdx</span><span class=p>.</span><span class=n>x</span> <span class=o>*</span> <span class=n>blockDim</span><span class=p>.</span><span class=n>x</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span><span class=p>(</span><span class=n>idx</span> <span class=o>&lt;</span> <span class=n>n</span><span class=p>)</span> <span class=n>out</span><span class=p>[</span><span class=n>idx</span><span class=p>]</span> <span class=o>=</span> <span class=n>a</span><span class=p>[</span><span class=n>idx</span><span class=p>]</span> <span class=o>+</span> <span class=n>b</span><span class=p>[</span><span class=n>idx</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>py</span><span class=o>::</span><span class=n>array_t</span><span class=o>&lt;</span><span class=kt>float</span><span class=o>&gt;</span> <span class=n>add_cuda</span><span class=p>(</span><span class=n>py</span><span class=o>::</span><span class=n>array_t</span><span class=o>&lt;</span><span class=kt>float</span><span class=o>&gt;</span> <span class=n>a</span> <span class=n>py</span><span class=o>::</span><span class=n>array_t</span><span class=o>&lt;</span><span class=kt>float</span><span class=o>&gt;</span> <span class=n>b</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=k>auto</span> <span class=n>buf_a</span> <span class=o>=</span> <span class=n>a</span><span class=p>.</span><span class=n>request</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=k>auto</span> <span class=n>buf_b</span> <span class=o>=</span> <span class=n>b</span><span class=p>.</span><span class=n>request</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span><span class=p>(</span><span class=n>buf_a</span><span class=p>.</span><span class=n>size</span> <span class=o>!=</span> <span class=n>buf_b</span><span class=p>.</span><span class=n>size</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>throw</span> <span class=n>std</span><span class=o>::</span><span class=n>runtime_error</span><span class=p>(</span><span class=s>&#34;Arrays must be same size&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=kt>int</span> <span class=n>n</span> <span class=o>=</span> <span class=n>buf_a</span><span class=p>.</span><span class=n>size</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=kt>float</span> <span class=o>*</span><span class=n>d_a</span> <span class=o>*</span><span class=n>d_b</span> <span class=o>*</span><span class=n>d_out</span>
</span></span><span class=line><span class=cl>    <span class=n>cudaMalloc</span><span class=p>(</span><span class=o>&amp;</span><span class=n>d_a</span> <span class=n>n</span><span class=o>*</span><span class=k>sizeof</span><span class=p>(</span><span class=kt>float</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=n>cudaMalloc</span><span class=p>(</span><span class=o>&amp;</span><span class=n>d_b</span> <span class=n>n</span><span class=o>*</span><span class=k>sizeof</span><span class=p>(</span><span class=kt>float</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=n>cudaMalloc</span><span class=p>(</span><span class=o>&amp;</span><span class=n>d_out</span> <span class=n>n</span><span class=o>*</span><span class=k>sizeof</span><span class=p>(</span><span class=kt>float</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=n>cudaMemcpy</span><span class=p>(</span><span class=n>d_a</span> <span class=n>buf_a</span><span class=p>.</span><span class=n>ptr</span> <span class=n>n</span><span class=o>*</span><span class=k>sizeof</span><span class=p>(</span><span class=kt>float</span><span class=p>)</span> <span class=n>cudaMemcpyHostToDevice</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>cudaMemcpy</span><span class=p>(</span><span class=n>d_b</span> <span class=n>buf_b</span><span class=p>.</span><span class=n>ptr</span> <span class=n>n</span><span class=o>*</span><span class=k>sizeof</span><span class=p>(</span><span class=kt>float</span><span class=p>)</span> <span class=n>cudaMemcpyHostToDevice</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=kt>int</span> <span class=n>block</span> <span class=o>=</span> <span class=mi>256</span> <span class=n>grid</span> <span class=o>=</span> <span class=p>(</span><span class=n>n</span> <span class=o>+</span> <span class=n>block</span> <span class=o>-</span> <span class=mi>1</span><span class=p>)</span><span class=o>/</span><span class=n>block</span>
</span></span><span class=line><span class=cl>    <span class=n>add_kernel</span><span class=o>&lt;&lt;&lt;</span><span class=n>grid</span> <span class=n>block</span><span class=o>&gt;&gt;&gt;</span><span class=p>(</span><span class=n>d_a</span> <span class=n>d_b</span> <span class=n>d_out</span> <span class=n>n</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>auto</span> <span class=n>result</span> <span class=o>=</span> <span class=n>py</span><span class=o>::</span><span class=n>array_t</span><span class=o>&lt;</span><span class=kt>float</span><span class=o>&gt;</span><span class=p>(</span><span class=n>n</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>cudaMemcpy</span><span class=p>(</span><span class=n>result</span><span class=p>.</span><span class=n>mutable_data</span><span class=p>()</span> <span class=n>d_out</span> <span class=n>n</span><span class=o>*</span><span class=k>sizeof</span><span class=p>(</span><span class=kt>float</span><span class=p>)</span> <span class=n>cudaMemcpyDeviceToHost</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>cudaFree</span><span class=p>(</span><span class=n>d_a</span><span class=p>)</span> <span class=n>cudaFree</span><span class=p>(</span><span class=n>d_b</span><span class=p>)</span> <span class=n>cudaFree</span><span class=p>(</span><span class=n>d_out</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>result</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>PYBIND11_MODULE</span><span class=p>(</span><span class=n>example</span> <span class=n>m</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=n>m</span><span class=p>.</span><span class=n>def</span><span class=p>(</span><span class=s>&#34;add_cuda&#34;</span> <span class=o>&amp;</span><span class=n>add_cuda</span> <span class=s>&#34;Add arrays on GPU with CUDA&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>Compile with:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>nvcc --compiler-options <span class=s1>&#39;-fPIC&#39;</span> -O3 -shared example_cuda.cu -o example_cuda.so -lcudart
</span></span></code></pre></div><p>Python sees the <code>.so</code> as a normal module while execution happens on GPU</p><hr><h2 id=6-understanding-so-files-wheels-and-python-abi>6 Understanding .so files, wheels, and Python ABI<a hidden class=anchor aria-hidden=true href=#6-understanding-so-files-wheels-and-python-abi>#</a></h2><p>Python ABI means <strong>Application Binary Interface</strong>. The chain is:</p><pre tabindex=0><code>Python → CPython ABI → .so → C++ functions
</code></pre><p>Pybind11 leverages this chain. Using setuptools we can compile C++ code into a <code>.so</code> file that Python can load dynamically. A <code>.so</code> file is not a standalone program it is a <strong>live binary module</strong>:</p><ul><li><code>.exe</code> standalone executable</li><li><code>.a</code> static library (copied in at compile time)</li><li><code>.so</code> shared library loaded at runtime</li></ul><p>Alternatives:</p><ul><li>Linux <code>.so</code></li><li>macOS <code>.dylib</code></li><li>Windows <code>.dll</code></li></ul><h3 id=anatomy-of-a-so-file>Anatomy of a <code>.so</code> file<a hidden class=anchor aria-hidden=true href=#anatomy-of-a-so-file>#</a></h3><p>A <code>.so</code> is an ELF file containing:</p><ol><li><p>Machine code - CPU instructions not bytecode</p></li><li><p>Symbol table - exported functions and variables for linking</p></li><li><p>Relocation info - how addresses are fixed at load time</p></li><li><p>Dynamic section - dependencies on other <code>.so</code> files</p></li><li><p>Sections:</p><ul><li><code>.text</code> executable code</li><li><code>.data</code> initialized globals</li><li><code>.bss</code> uninitialized globals</li><li><code>.rodata</code> constants</li></ul></li></ol><h3 id=runtime-usage>Runtime usage<a hidden class=anchor aria-hidden=true href=#runtime-usage>#</a></h3><ol><li>Program starts</li><li>Dynamic linker (<code>ld-linux.so</code>) loads <code>.so</code></li><li>Symbols resolved</li><li>Code mapped into memory</li><li>Functions callable like normal code</li></ol><p>Important note: <code>.so</code> files <strong>cannot be moved across CPU architectures</strong></p><h3 id=wheels>Wheels<a hidden class=anchor aria-hidden=true href=#wheels>#</a></h3><p>Wheels (<code>.whl</code>) are <strong>Python distribution packages</strong> that can include <code>.so</code> modules. They allow precompiled code to be installed with pip, avoiding the need for users to have a compiler:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>python setup.py bdist_wheel
</span></span><span class=line><span class=cl>pip install dist/example-0.1.0-cp311-cp311-linux_x86_64.whl
</span></span></code></pre></div><p>Key difference: <code>.so</code> is the <strong>runtime artifact</strong>. Wheel is the <strong>distribution format</strong> containing <code>.so</code> files, metadata, and Python package structure.</p><hr><h2 id=7-setup-script>7 Setup script<a hidden class=anchor aria-hidden=true href=#7-setup-script>#</a></h2><p>setup.py</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>setuptools</span> <span class=kn>import</span> <span class=n>setup</span><span class=p>,</span> <span class=n>Extension</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>pybind11</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>os</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>sys</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>setuptools.command.build_ext</span> <span class=kn>import</span> <span class=n>build_ext</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>subprocess</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Custom class to compile CUDA with nvcc</span>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>BuildExtWithCUDA</span><span class=p>(</span><span class=n>build_ext</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>build_extensions</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>ext</span> <span class=ow>in</span> <span class=bp>self</span><span class=o>.</span><span class=n>extensions</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=k>if</span> <span class=nb>getattr</span><span class=p>(</span><span class=n>ext</span><span class=p>,</span> <span class=s1>&#39;cuda&#39;</span><span class=p>,</span> <span class=kc>False</span><span class=p>):</span>
</span></span><span class=line><span class=cl>                <span class=bp>self</span><span class=o>.</span><span class=n>build_cuda_extension</span><span class=p>(</span><span class=n>ext</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=nb>super</span><span class=p>()</span><span class=o>.</span><span class=n>build_extensions</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>build_cuda_extension</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>ext</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=c1># Build the CUDA .cu file into a shared library</span>
</span></span><span class=line><span class=cl>        <span class=n>output_dir</span> <span class=o>=</span> <span class=n>os</span><span class=o>.</span><span class=n>path</span><span class=o>.</span><span class=n>abspath</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>build_lib</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>lib_file</span> <span class=o>=</span> <span class=n>os</span><span class=o>.</span><span class=n>path</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=n>output_dir</span><span class=p>,</span> <span class=n>ext</span><span class=o>.</span><span class=n>name</span> <span class=o>+</span> <span class=s2>&#34;.so&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>os</span><span class=o>.</span><span class=n>makedirs</span><span class=p>(</span><span class=n>output_dir</span><span class=p>,</span> <span class=n>exist_ok</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>cmd</span> <span class=o>=</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;nvcc&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;-O3&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;--compiler-options&#34;</span><span class=p>,</span> <span class=s2>&#34;&#39;-fPIC&#39;&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;-shared&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=o>*</span><span class=n>ext</span><span class=o>.</span><span class=n>sources</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;-o&#34;</span><span class=p>,</span> <span class=n>lib_file</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;-Xcompiler&#34;</span><span class=p>,</span> <span class=s2>&#34;-fPIC&#34;</span>
</span></span><span class=line><span class=cl>        <span class=p>]</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;Building CUDA extension:&#34;</span><span class=p>,</span> <span class=s2>&#34; &#34;</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=n>cmd</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=n>subprocess</span><span class=o>.</span><span class=n>check_call</span><span class=p>(</span><span class=s2>&#34; &#34;</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=n>cmd</span><span class=p>),</span> <span class=n>shell</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># CPU vectorized extension</span>
</span></span><span class=line><span class=cl><span class=n>cpu_ext</span> <span class=o>=</span> <span class=n>Extension</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;example&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=p>[</span><span class=s2>&#34;example.cpp&#34;</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=n>include_dirs</span><span class=o>=</span><span class=p>[</span><span class=n>pybind11</span><span class=o>.</span><span class=n>get_include</span><span class=p>()],</span>
</span></span><span class=line><span class=cl>    <span class=n>extra_compile_args</span><span class=o>=</span><span class=p>[</span><span class=s2>&#34;-O3&#34;</span><span class=p>,</span> <span class=s2>&#34;-march=native&#34;</span><span class=p>,</span> <span class=s2>&#34;-fopenmp&#34;</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=n>language</span><span class=o>=</span><span class=s2>&#34;c++&#34;</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># CUDA extension</span>
</span></span><span class=line><span class=cl><span class=n>cuda_ext</span> <span class=o>=</span> <span class=n>Extension</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;example_cuda&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=p>[</span><span class=s2>&#34;example_cuda.cu&#34;</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=n>include_dirs</span><span class=o>=</span><span class=p>[</span><span class=n>pybind11</span><span class=o>.</span><span class=n>get_include</span><span class=p>()],</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>cuda_ext</span><span class=o>.</span><span class=n>cuda</span> <span class=o>=</span> <span class=kc>True</span>  <span class=c1># mark it as CUDA</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>setup</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>name</span><span class=o>=</span><span class=s2>&#34;example&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>ext_modules</span><span class=o>=</span><span class=p>[</span><span class=n>cpu_ext</span><span class=p>,</span> <span class=n>cuda_ext</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=n>cmdclass</span><span class=o>=</span><span class=p>{</span><span class=s2>&#34;build_ext&#34;</span><span class=p>:</span> <span class=n>BuildExtWithCUDA</span><span class=p>},</span>
</span></span><span class=line><span class=cl>    <span class=n>zip_safe</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span></code></pre></div><hr><h2 id=8-demo-and-benchmark>8 Demo and Benchmark<a hidden class=anchor aria-hidden=true href=#8-demo-and-benchmark>#</a></h2><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>example</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>time</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Simple sanity check</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s2>&#34;Simple addition:&#34;</span><span class=p>,</span> <span class=n>example</span><span class=o>.</span><span class=n>add_simple</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Prepare large arrays for benchmarking</span>
</span></span><span class=line><span class=cl><span class=n>N</span> <span class=o>=</span> <span class=mi>10_000_000</span>
</span></span><span class=line><span class=cl><span class=n>a</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>rand</span><span class=p>(</span><span class=n>N</span><span class=p>)</span><span class=o>.</span><span class=n>astype</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>float32</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>b</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>rand</span><span class=p>(</span><span class=n>N</span><span class=p>)</span><span class=o>.</span><span class=n>astype</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>float32</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Vectorized CPU addition</span>
</span></span><span class=line><span class=cl><span class=n>start_cpu</span> <span class=o>=</span> <span class=n>time</span><span class=o>.</span><span class=n>time</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>c_cpu</span> <span class=o>=</span> <span class=n>example</span><span class=o>.</span><span class=n>add_vectorized</span><span class=p>(</span><span class=n>a</span><span class=p>,</span> <span class=n>b</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>end_cpu</span> <span class=o>=</span> <span class=n>time</span><span class=o>.</span><span class=n>time</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;CPU vectorized addition first 10 elements: </span><span class=si>{</span><span class=n>c_cpu</span><span class=p>[:</span><span class=mi>10</span><span class=p>]</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;CPU vectorized addition time: </span><span class=si>{</span><span class=n>end_cpu</span> <span class=o>-</span> <span class=n>start_cpu</span><span class=si>:</span><span class=s2>.6f</span><span class=si>}</span><span class=s2> seconds&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># CUDA GPU addition</span>
</span></span><span class=line><span class=cl><span class=n>start_gpu</span> <span class=o>=</span> <span class=n>time</span><span class=o>.</span><span class=n>time</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>c_gpu</span> <span class=o>=</span> <span class=n>example</span><span class=o>.</span><span class=n>add_cuda</span><span class=p>(</span><span class=n>a</span><span class=p>,</span> <span class=n>b</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>end_gpu</span> <span class=o>=</span> <span class=n>time</span><span class=o>.</span><span class=n>time</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;GPU CUDA addition first 10 elements: </span><span class=si>{</span><span class=n>c_gpu</span><span class=p>[:</span><span class=mi>10</span><span class=p>]</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;GPU CUDA addition time: </span><span class=si>{</span><span class=n>end_gpu</span> <span class=o>-</span> <span class=n>start_gpu</span><span class=si>:</span><span class=s2>.6f</span><span class=si>}</span><span class=s2> seconds&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Verify correctness</span>
</span></span><span class=line><span class=cl><span class=k>if</span> <span class=n>np</span><span class=o>.</span><span class=n>allclose</span><span class=p>(</span><span class=n>c_cpu</span><span class=p>,</span> <span class=n>c_gpu</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;CPU and GPU results match!&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;Warning: CPU and GPU results do not match!&#34;</span><span class=p>)</span>
</span></span></code></pre></div></div><footer class=post-footer><ul class=post-tags><li><a href=http://localhost:1313/tags/python/>Python</a></li><li><a href=http://localhost:1313/tags/numpy/>Numpy</a></li><li><a href=http://localhost:1313/tags/pybind/>Pybind</a></li><li><a href=http://localhost:1313/tags/cpp/>Cpp</a></li><li><a href=http://localhost:1313/tags/simd/>SIMD</a></li><li><a href=http://localhost:1313/tags/cuda/>CUDA</a></li><li><a href=http://localhost:1313/tags/openmp/>OpenMP</a></li><li><a href=http://localhost:1313/tags/scientific-computing/>Scientific Computing</a></li><li><a href=http://localhost:1313/tags/extensions/>Extensions</a></li><li><a href=http://localhost:1313/tags/packaging/>Packaging</a></li><li><a href=http://localhost:1313/tags/abi/>Abi</a></li></ul><nav class=paginav><a class=next href=http://localhost:1313/posts/memory-of-forgotten/><span class=title>Next »</span><br><span>NOTES: Memory of Forgotten</span></a></nav></footer></article></main><footer class=footer><span>&copy; 2026 <a href=http://localhost:1313/>T|A</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>