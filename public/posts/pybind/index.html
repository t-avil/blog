<!doctype html><html lang=en dir=auto><head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>INTRO: How to Build Your Own Version of NumPy | T|A</title><meta name=keywords content="cuda,python,numpy,pybind,cpp,SIMD,CUDA,OpenMP,scientific computing,extensions,packaging,abi"><meta name=description content="From minimal pybind11 demos to vectorized CPU routines and CUDA acceleration learn to build Python C++ extensions and understand so files wheel distribution and Python ABI."><meta name=author content="Me"><link rel=canonical href=https://canonical.url/to/page><link crossorigin=anonymous href=/assets/css/stylesheet.3f7ba6a00d316a1658af1e52b60f5592bfd3f63e1683217d447958625c9fec2a.css integrity="sha256-P3umoA0xahZYrx5Stg9Vkr/T9j4WgyF9RHlYYlyf7Co=" rel="preload stylesheet" as=style><link rel=icon href=http://localhost:1313/favicon.ico><link rel=icon type=image/png sizes=16x16 href=http://localhost:1313/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=http://localhost:1313/favicon-32x32.png><link rel=apple-touch-icon href=http://localhost:1313/apple-touch-icon.png><link rel=mask-icon href=http://localhost:1313/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=http://localhost:1313/posts/pybind/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:url" content="http://localhost:1313/posts/pybind/"><meta property="og:site_name" content="T|A"><meta property="og:title" content="INTRO: How to Build Your Own Version of NumPy"><meta property="og:description" content="From minimal pybind11 demos to vectorized CPU routines and CUDA acceleration learn to build Python C++ extensions and understand so files wheel distribution and Python ABI."><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2026-01-21T23:27:20-08:00"><meta property="article:modified_time" content="2026-01-21T23:27:20-08:00"><meta property="article:tag" content="Python"><meta property="article:tag" content="Numpy"><meta property="article:tag" content="Pybind"><meta property="article:tag" content="Cpp"><meta property="article:tag" content="SIMD"><meta property="article:tag" content="CUDA"><meta property="og:image" content="http://localhost:1313/images/papermod-cover.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="http://localhost:1313/images/papermod-cover.png"><meta name=twitter:title content="INTRO: How to Build Your Own Version of NumPy"><meta name=twitter:description content="From minimal pybind11 demos to vectorized CPU routines and CUDA acceleration learn to build Python C++ extensions and understand so files wheel distribution and Python ABI."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"http://localhost:1313/posts/"},{"@type":"ListItem","position":2,"name":"INTRO: How to Build Your Own Version of NumPy","item":"http://localhost:1313/posts/pybind/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"INTRO: How to Build Your Own Version of NumPy","name":"INTRO: How to Build Your Own Version of NumPy","description":"From minimal pybind11 demos to vectorized CPU routines and CUDA acceleration learn to build Python C++ extensions and understand so files wheel distribution and Python ABI.","keywords":["cuda","python","numpy","pybind","cpp","SIMD","CUDA","OpenMP","scientific computing","extensions","packaging","abi"],"articleBody":"Python is expressive and flexible but slow for heavy numeric computation. Libraries like NumPy combine Python with fast compiled backends to speed up arrays and matrix operations. With Pybind11, you can write C++ or CUDA code, expose it to Python, and package it cross-platform.\nIn this post, we’ll cover building vectorized CPU functions with SIMD and OpenMP, GPU acceleration, compiling .so modules, distributing via wheels, and understanding the Python ABI. These examples serve as notes for anyone curious about how CuPy, a GPU-powered NumPy alternative, works under the hood.\n1 Environment setup On Rocky Linux install required tools\nsudo dnf install -y python3 python3-devel gcc gcc-c++ make cmake pip3 install --user pybind11 wheel setuptools numpy Check Python and compiler\npython3 --version gcc --version python3 -m pybind11 --includes 2 Project structure We will build two functions:\nadd_vectorized optimized with SIMD, OpenMP, and BLAS add_cuda GPU accelerated Directory layout:\n$ tree -L 2 . ├── benchmark.py ├── example_cpu.cpp ├── example_cuda.cu ├── example (will be converted to example_src due to name collision) ├── example_cuda.so (we will compile this guy) └── __init__.py ├── Makefile ├── pyproject.toml └── setup.py 3 Simple addition function example.cpp\n#include namespace py = pybind11 int add_simple(int a int b) { return a + b } PYBIND11_MODULE(example m) { m.def(\"add_simple\" \u0026add_simple \"Add two integers\") } Build and test\npython3 setup.py build_ext --inplace python3 \u003e\u003e\u003e import example \u003e\u003e\u003e example.add_simple(2 3) 5 This produces a .so shared object that Python dynamically loads.\n4 Vectorized CPU function High performance numeric code relies on SIMD (single instruction multiple data), multi-core parallelism (OpenMP), and tuned linear algebra libraries (BLAS/LAPACK).\nSIMD Modern CPUs have vector registers AVX2, AVX-512, or NEON. Operations like addition, multiplication, or dot product can process multiple elements at once. You can use intrinsics or rely on compiler auto-vectorization. Example using AVX2:\n#include void add_float_avx(float* a float* b float* out int n) { for (int i = 0 i \u003c n i += 8) { __m256 va = _mm256_loadu_ps(a + i) __m256 vb = _mm256_loadu_ps(b + i) __m256 vc = _mm256_add_ps(va vb) _mm256_storeu_ps(out + i vc) } } OpenMP Parallelize loops across CPU cores:\n#pragma omp parallel for for (int i = 0 i \u003c N i++) { out[i] = a[i] + b[i] } BLAS/LAPACK For linear algebra rely on optimized libraries like OpenBLAS or MKL. Pybind11 can expose these routines to Python. Example: cblas_sgemm for matrix multiplication. We are not using these guys for now.\nFull Pybind example ./example_cpu.cpp\n#include #include #include #ifdef _OPENMP #include #endif namespace py = pybind11; py::array_t\u003cfloat\u003e add_vectorized(py::array_t\u003cfloat\u003e a, py::array_t\u003cfloat\u003e b) { auto buf_a = a.request(); auto buf_b = b.request(); if (buf_a.size != buf_b.size) { throw std::runtime_error(\"Arrays must be same size\"); } size_t n = buf_a.size; size_t n8 = (n / 8) * 8; auto result = py::array_t\u003cfloat\u003e(n); auto buf_r = result.request(); float* ptr_a = static_cast\u003cfloat*\u003e(buf_a.ptr); float* ptr_b = static_cast\u003cfloat*\u003e(buf_b.ptr); float* ptr_r = static_cast\u003cfloat*\u003e(buf_r.ptr); // AVX + OpenMP (canonical loop) #pragma omp parallel for for (size_t i = 0; i \u003c n8; i += 8) { __m256 va = _mm256_loadu_ps(ptr_a + i); __m256 vb = _mm256_loadu_ps(ptr_b + i); __m256 vr = _mm256_add_ps(va, vb); _mm256_storeu_ps(ptr_r + i, vr); } for (size_t i = n8; i \u003c n; ++i) { ptr_r[i] = ptr_a[i] + ptr_b[i]; } return result; } PYBIND11_MODULE(example_cpu, m) { m.def(\"add_vectorized\", \u0026add_vectorized, \"Vectorized float addition with SIMD and OpenMP\"); } 5 CUDA GPU function ./example_cuda.cu\n#include #include #include #include namespace py = pybind11; __global__ void add_kernel(const float* a, const float* b, float* out, int n) { int idx = blockIdx.x * blockDim.x + threadIdx.x; if (idx \u003c n) { out[idx] = a[idx] + b[idx]; } } py::array_t\u003cfloat\u003e add_cuda(py::array_t\u003cfloat\u003e a, py::array_t\u003cfloat\u003e b) { auto buf_a = a.request(); auto buf_b = b.request(); if (buf_a.size != buf_b.size) { throw std::runtime_error(\"Arrays must have the same size\"); } int n = static_cast\u003cint\u003e(buf_a.size); float* d_a = nullptr; float* d_b = nullptr; float* d_out = nullptr; cudaMalloc(\u0026d_a, n * sizeof(float)); cudaMalloc(\u0026d_b, n * sizeof(float)); cudaMalloc(\u0026d_out, n * sizeof(float)); cudaMemcpy(d_a, buf_a.ptr, n * sizeof(float), cudaMemcpyHostToDevice); cudaMemcpy(d_b, buf_b.ptr, n * sizeof(float), cudaMemcpyHostToDevice); int block = 256; int grid = (n + block - 1) / block; add_kernel\u003c\u003c\u003cgrid, block\u003e\u003e\u003e(d_a, d_b, d_out, n); auto result = py::array_t\u003cfloat\u003e(n); cudaMemcpy(result.mutable_data(), d_out, n * sizeof(float), cudaMemcpyDeviceToHost); cudaFree(d_a); cudaFree(d_b); cudaFree(d_out); return result; } PYBIND11_MODULE(example_cuda, m) { m.def(\"add_cuda\", \u0026add_cuda, \"Add arrays on GPU using CUDA\"); } Compile with:\nnvcc -O3 --compiler-options '-fPIC' -shared example_cuda.cu `python3 -m pybind11 --includes` -o example/example_cuda.so -lcudart Python sees the .so as a normal module while execution happens on GPU\n6 Understanding .so files, wheels, and Python ABI Python ABI means Application Binary Interface. The chain is:\nPython → CPython ABI → .so → C++ functions Pybind11 leverages this chain. Using setuptools we can compile C++ code into a .so file that Python can load dynamically. A .so file is not a standalone program it is a live binary module:\n.exe standalone executable .a static library (copied in at compile time) .so shared library loaded at runtime Alternatives:\nLinux .so macOS .dylib Windows .dll Anatomy of a .so file A .so is an ELF file containing:\nMachine code - CPU instructions not bytecode\nSymbol table - exported functions and variables for linking\nRelocation info - how addresses are fixed at load time\nDynamic section - dependencies on other .so files\nSections:\n.text executable code .data initialized globals .bss uninitialized globals .rodata constants Runtime usage Program starts Dynamic linker (ld-linux.so) loads .so Symbols resolved Code mapped into memory Functions callable like normal code Important note: .so files cannot be moved across CPU architectures\nWheels Wheels (.whl) are Python distribution packages that can include .so modules. They allow precompiled code to be installed with pip, avoiding the need for users to have a compiler:\npython3 -m build pip install dist/example-0.1.0-*.whl --force-reinstall Key difference: .so is the runtime artifact. Wheel is the distribution format containing .so files, metadata, and Python package structure.\n7 Setup script setup.py\nfrom setuptools import setup, Extension import pybind11 import os cpu_ext = Extension( name=\"example.example_cpu\", sources=[\"example_cpu.cpp\"], include_dirs=[pybind11.get_include()], extra_compile_args=[\"-O3\", \"-march=native\", \"-fopenmp\"], extra_link_args=[\"-fopenmp\"], language=\"c++\", ) cuda_so = os.path.join(\"example\", \"example_cuda.so\") if not os.path.exists(cuda_so): raise RuntimeError( \"example_cuda.so not found.\\n\" \"Build it first with nvcc before running setup.py.\" ) setup( name=\"example\", version=\"0.1.0\", packages=[\"example\"], package_data={ \"example\": [\"example_cuda.so\"], }, ext_modules=[cpu_ext], zip_safe=False, ) 8 Demo and Benchmark import example import numpy as np import time # ----------------------------- # Config # ----------------------------- N = 1_000_000_000 REPS = 10 PRINT_N = 10 # ----------------------------- # Prepare arrays # ----------------------------- a = np.random.rand(N).astype(np.float32) b = np.random.rand(N).astype(np.float32) # ----------------------------- # CPU benchmark # ----------------------------- cpu_times = [] for _ in range(REPS): start = time.time() c_cpu = example.add_vectorized(a, b) end = time.time() cpu_times.append(end - start) avg_cpu = np.mean(cpu_times) print(f\"CPU first {PRINT_N} elements: {c_cpu[:PRINT_N]}\") print(f\"CPU total time: {avg_cpu:.6f}s, per element: {avg_cpu/N*1e9:.3f} ns/element\") # ----------------------------- # GPU benchmark (total) # ----------------------------- # Warm-up example.add_cuda(a, b) gpu_times = [] for _ in range(REPS): start = time.time() c_gpu = example.add_cuda(a, b) end = time.time() gpu_times.append(end - start) avg_gpu_total = np.mean(gpu_times) print(f\"GPU first {PRINT_N} elements: {c_gpu[:PRINT_N]}\") print(f\"GPU total time: {avg_gpu_total:.6f}s, per element: {avg_gpu_total/N*1e9:.3f} ns/element\") # ----------------------------- # Verify correctness # ----------------------------- if np.allclose(c_cpu, c_gpu): print(\"CPU and GPU results match!\") else: print(\"CPU and GPU results do not match!\") GPU overhead is significant for small arrays because of memory transfer latency. With larger arrays, GPU naturally outperforms due to massive parallelization.\nBenchmark results at 1B floats for cpu/gpu simple examples in pybind.\n9 Makefile \u0026 Pyproject.toml Makefile:\nall: run example/example_cuda.so: example_cuda.cu mkdir -p example nvcc -O3 --compiler-options '-fPIC' -shared example_cuda.cu `python3 -m pybind11 --includes` -o example/example_cuda.so -lcudart example/__init__.py: example/example_cuda.so echo \"from .example_cuda import *\" \u003e example/__init__.py echo \"from .example_cpu import *\" \u003e\u003e example/__init__.py wheel: example/__init__.py python3 -m build mv ./example ./example_src install: wheel pip install dist/example-0.1.0-*.whl --force-reinstall run: install python3 ./benchmark.py clean: pip uninstall example -y rm -rf build dist example.egg-info example-0.1.0 example pyproject.toml:\n[build-system] requires = [ \"setuptools\u003e=64\", \"wheel\", \"pybind11\u003e=2.10\" ] build-backend = \"setuptools.build_meta\" This allows building the package with python3 build and distributing as a wheel.\n10 Python Package Lifecycle \u0026 Dependency Management Understanding how Python modules, packages, compiled extensions, and dependencies interact is crucial when building libraries like your own NumPy clone. Here’s a detailed breakdown:\n10.1 Modules and Packages Module: a single .py file containing Python code-functions, classes, constants-that can be imported. Example: # utils.py def add(a, b): return a + b Package: a directory with an __init__.py file (even if empty) that tells Python “this is a package.” Packages can contain multiple modules and sub-packages, creating a hierarchical structure: mypackage/ ├── __init__.py ├── utils.py └── subpackage/ ├── __init__.py └── math_ops.py Packages may also include:\nCompiled extensions (.so on Linux, .pyd on Windows), typically generated via pybind11 or Cython. Data files (images, JSON, CSV, etc.) Metadata files (setup.py, pyproject.toml, MANIFEST.in) describing the package, version, dependencies, and entry points. 10.2 Installation Process When you install a package locally or via PyPI:\npip install ./mypackage Metadata parsing: Pip reads setup.py or pyproject.toml to discover package info and dependencies. Dependency resolution: Pip determines which other packages are needed, including versions. Compilation of extensions: Any .cpp or .cu files are compiled into .so/.pyd using the system compiler. Copying files: Python code, compiled binaries, and package data are copied into the site-packages directory of your environment. Isolation via virtual environments: If you’re inside a venv, this installation is isolated from the system Python. This allows multiple versions of the same package in different projects without conflict. Metadata storage: Pip generates .dist-info folders containing package metadata, dependencies, and file records for uninstallation or introspection. 10.3 Wheels and Distribution Wheel (.whl): a standardized binary distribution format for Python. Wheels can include precompiled extensions so users don’t need a compiler. Platform-specific if compiled extensions exist; pure Python wheels work across all platforms. Source distribution (.tar.gz) contains the raw Python/C++ source and requires compilation at install time. Uploading: twine upload dist/mypackage-0.1.0-py3-none-any.whl Users can then install via: pip install mypackage The wheel contains everything pip needs: Python code, compiled binaries, metadata, and optional console scripts. 10.4 Python ABI and Compiled Extensions Python ABI (Application Binary Interface) defines how compiled extensions (.so or .pyd) interact with the Python interpreter.\nPybind11 wraps C++ or CUDA code and exposes it through the CPython ABI so that Python can dynamically load functions at runtime.\nLife cycle for compiled extensions:\n.so or .pyd is compiled. Python imports the module. The system loader dynamically maps the machine code into memory. Python calls functions in the extension as if they were regular Python functions. .so files cannot be moved across CPU architectures; they must be recompiled for each target CPU.\n10.5 Dependency Management Modern Python projects often include external dependencies. Dependencies can be:\nPyPI packages (e.g., numpy, scipy) Git repositories (private or public) Example in pyproject.toml or requirements.txt:\ngit+https://github.com/username/mylib.git@v1.2.3#egg=mylib When pip installs this dependency:\nIt fetches the repository. Checks out the specified commit, branch, or tag. Installs it alongside standard PyPI packages. Pip itself does not resolve Git versions from lock files (like uv.lock); it only installs the URL you provide.\nTools like Poetry or pip-tools sit on top of pip:\nThey generate lock files (poetry.lock or requirements.txt) that pin exact versions and commits. They ensure reproducible installations across environments. Version specifiers:\n==1.2.3 → exact version \u003e=1.2.0,\u003c2.0.0 → compatible range ~=1.2.3 → compatible with 1.2.x patches Unlike Node.js/npm, Python does not deduplicate versions automatically; multiple versions may coexist in site-packages. Tools like Poetry or uv resolve versions into a deterministic environment.\n10.6 Full Lifecycle Develop your module/package. Structure it with __init__.py, metadata, optional compiled extensions, and data files. Test locally in a virtual environment. Build sdist or wheel. Publish to PyPI or private repository. Install in another environment with pip. Python handles module resolution, dynamic loading, and dependency management. Extra notes:\nPackages can include console scripts (entry points), type stubs, and runtime-accessible data. Compiled extensions bridge Python with high-performance C++/CUDA code. With proper packaging, users can run your library without a compiler, achieving both ease of installation and high performance. ","wordCount":"1977","inLanguage":"en","image":"http://localhost:1313/images/papermod-cover.png","datePublished":"2026-01-21T23:27:20-08:00","dateModified":"2026-01-21T23:27:20-08:00","author":{"@type":"Person","name":"Me"},"mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:1313/posts/pybind/"},"publisher":{"@type":"Organization","name":"T|A","logo":{"@type":"ImageObject","url":"http://localhost:1313/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=http://localhost:1313/ accesskey=h title="T|A (Alt + H)">T|A</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=http://localhost:1313/about title=About><span>About</span></a></li><li><a href=http://localhost:1313/chronicles title=Chronicles><span>Chronicles</span></a></li><li><a href=http://localhost:1313/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=http://localhost:1313/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://github.com/t-avil title=Github><span>Github</span>&nbsp;
<svg fill="none" shape-rendering="geometricPrecision" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=http://localhost:1313/>Home</a>&nbsp;»&nbsp;<a href=http://localhost:1313/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">INTRO: How to Build Your Own Version of NumPy</h1><div class=post-description>From minimal pybind11 demos to vectorized CPU routines and CUDA acceleration learn to build Python C++ extensions and understand so files wheel distribution and Python ABI.</div><div class=post-meta><span title='2026-01-21 23:27:20 -0800 PST'>January 21, 2026</span>&nbsp;·&nbsp;10 min&nbsp;·&nbsp;1977 words&nbsp;·&nbsp;Me&nbsp;|&nbsp;<a href=https://github.com/t-avil/blog/tree/main/content/posts/pybind.md rel="noopener noreferrer edit" target=_blank>Suggest Changes</a></div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><nav id=TableOfContents><ul><li><a href=#1-environment-setup>1 Environment setup</a></li><li><a href=#2-project-structure>2 Project structure</a></li><li><a href=#3-simple-addition-function>3 Simple addition function</a></li><li><a href=#4-vectorized-cpu-function>4 Vectorized CPU function</a><ul><li><a href=#simd>SIMD</a></li><li><a href=#openmp>OpenMP</a></li><li><a href=#blaslapack>BLAS/LAPACK</a></li><li><a href=#full-pybind-example>Full Pybind example</a></li></ul></li><li><a href=#5-cuda-gpu-function>5 CUDA GPU function</a></li><li><a href=#6-understanding-so-files-wheels-and-python-abi>6 Understanding .so files, wheels, and Python ABI</a><ul><li><a href=#anatomy-of-a-so-file>Anatomy of a <code>.so</code> file</a></li><li><a href=#runtime-usage>Runtime usage</a></li><li><a href=#wheels>Wheels</a></li></ul></li><li><a href=#7-setup-script>7 Setup script</a></li><li><a href=#8-demo-and-benchmark>8 Demo and Benchmark</a></li><li><a href=#9-makefile--pyprojecttoml>9 Makefile & Pyproject.toml</a></li><li><a href=#10-python-package-lifecycle--dependency-management>10 Python Package Lifecycle & Dependency Management</a><ul><li><a href=#101-modules-and-packages>10.1 Modules and Packages</a></li><li><a href=#102-installation-process>10.2 Installation Process</a></li><li><a href=#103-wheels-and-distribution>10.3 Wheels and Distribution</a></li><li><a href=#104-python-abi-and-compiled-extensions>10.4 Python ABI and Compiled Extensions</a></li><li><a href=#105-dependency-management>10.5 Dependency Management</a></li><li><a href=#106-full-lifecycle>10.6 Full Lifecycle</a></li></ul></li></ul></nav></div></details></div><div class=post-content><p>Python is expressive and flexible but <strong>slow for heavy numeric computation</strong>. Libraries like <a href=https://numpy.org/>NumPy</a> combine Python with fast compiled backends to speed up arrays and matrix operations. With <a href=https://pybind11.readthedocs.io/>Pybind11</a>, you can write <strong>C++ or CUDA code</strong>, expose it to Python, and package it cross-platform.</p><p>In this post, we’ll cover building <strong>vectorized CPU functions with SIMD and <a href=https://www.openmp.org/>OpenMP</a></strong>, <strong>GPU acceleration</strong>, compiling <code>.so</code> modules, distributing via wheels, and understanding the <a href=https://docs.python.org/3/c-api/abi.html>Python ABI</a>. These examples serve as notes for anyone curious about how <a href=https://github.com/cupy/cupy>CuPy</a>, a GPU-powered NumPy alternative, works under the hood.</p><hr><h2 id=1-environment-setup>1 Environment setup<a hidden class=anchor aria-hidden=true href=#1-environment-setup>#</a></h2><p>On Rocky Linux install required tools</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>sudo dnf install -y python3 python3-devel gcc gcc-c++ make cmake
</span></span><span class=line><span class=cl>pip3 install --user pybind11 wheel setuptools numpy
</span></span></code></pre></div><p>Check Python and compiler</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>python3 --version
</span></span><span class=line><span class=cl>gcc --version
</span></span><span class=line><span class=cl>python3 -m pybind11 --includes
</span></span></code></pre></div><hr><h2 id=2-project-structure>2 Project structure<a hidden class=anchor aria-hidden=true href=#2-project-structure>#</a></h2><p>We will build two functions:</p><ul><li><code>add_vectorized</code> optimized with SIMD, OpenMP, and BLAS</li><li><code>add_cuda</code> GPU accelerated</li></ul><p>Directory layout:</p><pre tabindex=0><code>$ tree -L 2
.
├── benchmark.py
├── example_cpu.cpp
├── example_cuda.cu
├── example (will be converted to example_src due to name collision)
    ├── example_cuda.so (we will compile this guy)
    └── __init__.py
├── Makefile
├── pyproject.toml
└── setup.py
</code></pre><hr><h2 id=3-simple-addition-function>3 Simple addition function<a hidden class=anchor aria-hidden=true href=#3-simple-addition-function>#</a></h2><p>example.cpp</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-cpp data-lang=cpp><span class=line><span class=cl><span class=cp>#include</span> <span class=cpf>&lt;pybind11/pybind11.h&gt;</span><span class=cp>
</span></span></span><span class=line><span class=cl><span class=cp></span><span class=k>namespace</span> <span class=n>py</span> <span class=o>=</span> <span class=n>pybind11</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kt>int</span> <span class=n>add_simple</span><span class=p>(</span><span class=kt>int</span> <span class=n>a</span> <span class=kt>int</span> <span class=n>b</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>a</span> <span class=o>+</span> <span class=n>b</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>PYBIND11_MODULE</span><span class=p>(</span><span class=n>example</span> <span class=n>m</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=n>m</span><span class=p>.</span><span class=n>def</span><span class=p>(</span><span class=s>&#34;add_simple&#34;</span> <span class=o>&amp;</span><span class=n>add_simple</span> <span class=s>&#34;Add two integers&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>Build and test</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>python3 setup.py build_ext --inplace
</span></span><span class=line><span class=cl>python3
</span></span><span class=line><span class=cl>&gt;&gt;&gt; import example
</span></span><span class=line><span class=cl>&gt;&gt;&gt; example.add_simple<span class=o>(</span><span class=m>2</span> 3<span class=o>)</span>
</span></span><span class=line><span class=cl><span class=m>5</span>
</span></span></code></pre></div><p>This produces a <code>.so</code> shared object that Python dynamically loads.</p><hr><h2 id=4-vectorized-cpu-function>4 Vectorized CPU function<a hidden class=anchor aria-hidden=true href=#4-vectorized-cpu-function>#</a></h2><p>High performance numeric code relies on <strong>SIMD</strong> (single instruction multiple data), <strong>multi-core parallelism</strong> (OpenMP), and <strong>tuned linear algebra libraries</strong> (BLAS/LAPACK).</p><h3 id=simd>SIMD<a hidden class=anchor aria-hidden=true href=#simd>#</a></h3><p>Modern CPUs have vector registers AVX2, AVX-512, or NEON. Operations like addition, multiplication, or dot product can process multiple elements at once. You can use intrinsics or rely on compiler auto-vectorization. Example using AVX2:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-cpp data-lang=cpp><span class=line><span class=cl><span class=cp>#include</span> <span class=cpf>&lt;immintrin.h&gt;</span><span class=cp>
</span></span></span><span class=line><span class=cl><span class=cp></span>
</span></span><span class=line><span class=cl><span class=kt>void</span> <span class=nf>add_float_avx</span><span class=p>(</span><span class=kt>float</span><span class=o>*</span> <span class=n>a</span> <span class=kt>float</span><span class=o>*</span> <span class=n>b</span> <span class=kt>float</span><span class=o>*</span> <span class=n>out</span> <span class=kt>int</span> <span class=n>n</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=p>(</span><span class=kt>int</span> <span class=n>i</span> <span class=o>=</span> <span class=mi>0</span> <span class=n>i</span> <span class=o>&lt;</span> <span class=n>n</span> <span class=n>i</span> <span class=o>+=</span> <span class=mi>8</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=n>__m256</span> <span class=n>va</span> <span class=o>=</span> <span class=n>_mm256_loadu_ps</span><span class=p>(</span><span class=n>a</span> <span class=o>+</span> <span class=n>i</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>__m256</span> <span class=n>vb</span> <span class=o>=</span> <span class=n>_mm256_loadu_ps</span><span class=p>(</span><span class=n>b</span> <span class=o>+</span> <span class=n>i</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>__m256</span> <span class=n>vc</span> <span class=o>=</span> <span class=n>_mm256_add_ps</span><span class=p>(</span><span class=n>va</span> <span class=n>vb</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>_mm256_storeu_ps</span><span class=p>(</span><span class=n>out</span> <span class=o>+</span> <span class=n>i</span> <span class=n>vc</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><h3 id=openmp>OpenMP<a hidden class=anchor aria-hidden=true href=#openmp>#</a></h3><p>Parallelize loops across CPU cores:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-cpp data-lang=cpp><span class=line><span class=cl><span class=cp>#pragma omp parallel for
</span></span></span><span class=line><span class=cl><span class=cp></span><span class=k>for</span> <span class=p>(</span><span class=kt>int</span> <span class=n>i</span> <span class=o>=</span> <span class=mi>0</span> <span class=n>i</span> <span class=o>&lt;</span> <span class=n>N</span> <span class=n>i</span><span class=o>++</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=n>out</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=o>=</span> <span class=n>a</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=o>+</span> <span class=n>b</span><span class=p>[</span><span class=n>i</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><h3 id=blaslapack>BLAS/LAPACK<a hidden class=anchor aria-hidden=true href=#blaslapack>#</a></h3><p>For linear algebra rely on optimized libraries like OpenBLAS or MKL. Pybind11 can expose these routines to Python. Example: <code>cblas_sgemm</code> for matrix multiplication. We are not using these guys for now.</p><h3 id=full-pybind-example>Full Pybind example<a hidden class=anchor aria-hidden=true href=#full-pybind-example>#</a></h3><p>./example_cpu.cpp</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-cpp data-lang=cpp><span class=line><span class=cl><span class=cp>#include</span> <span class=cpf>&lt;immintrin.h&gt;</span><span class=cp>
</span></span></span><span class=line><span class=cl><span class=cp>#include</span> <span class=cpf>&lt;pybind11/numpy.h&gt;</span><span class=cp>
</span></span></span><span class=line><span class=cl><span class=cp>#include</span> <span class=cpf>&lt;pybind11/pybind11.h&gt;</span><span class=cp>
</span></span></span><span class=line><span class=cl><span class=cp></span>
</span></span><span class=line><span class=cl><span class=cp>#ifdef _OPENMP
</span></span></span><span class=line><span class=cl><span class=cp>#include</span> <span class=cpf>&lt;omp.h&gt;</span><span class=cp>
</span></span></span><span class=line><span class=cl><span class=cp>#endif
</span></span></span><span class=line><span class=cl><span class=cp></span>
</span></span><span class=line><span class=cl><span class=k>namespace</span> <span class=n>py</span> <span class=o>=</span> <span class=n>pybind11</span><span class=p>;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>py</span><span class=o>::</span><span class=n>array_t</span><span class=o>&lt;</span><span class=kt>float</span><span class=o>&gt;</span> <span class=n>add_vectorized</span><span class=p>(</span><span class=n>py</span><span class=o>::</span><span class=n>array_t</span><span class=o>&lt;</span><span class=kt>float</span><span class=o>&gt;</span> <span class=n>a</span><span class=p>,</span> <span class=n>py</span><span class=o>::</span><span class=n>array_t</span><span class=o>&lt;</span><span class=kt>float</span><span class=o>&gt;</span> <span class=n>b</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>  <span class=k>auto</span> <span class=n>buf_a</span> <span class=o>=</span> <span class=n>a</span><span class=p>.</span><span class=n>request</span><span class=p>();</span>
</span></span><span class=line><span class=cl>  <span class=k>auto</span> <span class=n>buf_b</span> <span class=o>=</span> <span class=n>b</span><span class=p>.</span><span class=n>request</span><span class=p>();</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=k>if</span> <span class=p>(</span><span class=n>buf_a</span><span class=p>.</span><span class=n>size</span> <span class=o>!=</span> <span class=n>buf_b</span><span class=p>.</span><span class=n>size</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=k>throw</span> <span class=n>std</span><span class=o>::</span><span class=n>runtime_error</span><span class=p>(</span><span class=s>&#34;Arrays must be same size&#34;</span><span class=p>);</span>
</span></span><span class=line><span class=cl>  <span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=n>size_t</span> <span class=n>n</span> <span class=o>=</span> <span class=n>buf_a</span><span class=p>.</span><span class=n>size</span><span class=p>;</span>
</span></span><span class=line><span class=cl>  <span class=n>size_t</span> <span class=n>n8</span> <span class=o>=</span> <span class=p>(</span><span class=n>n</span> <span class=o>/</span> <span class=mi>8</span><span class=p>)</span> <span class=o>*</span> <span class=mi>8</span><span class=p>;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=k>auto</span> <span class=n>result</span> <span class=o>=</span> <span class=n>py</span><span class=o>::</span><span class=n>array_t</span><span class=o>&lt;</span><span class=kt>float</span><span class=o>&gt;</span><span class=p>(</span><span class=n>n</span><span class=p>);</span>
</span></span><span class=line><span class=cl>  <span class=k>auto</span> <span class=n>buf_r</span> <span class=o>=</span> <span class=n>result</span><span class=p>.</span><span class=n>request</span><span class=p>();</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=kt>float</span><span class=o>*</span> <span class=n>ptr_a</span> <span class=o>=</span> <span class=k>static_cast</span><span class=o>&lt;</span><span class=kt>float</span><span class=o>*&gt;</span><span class=p>(</span><span class=n>buf_a</span><span class=p>.</span><span class=n>ptr</span><span class=p>);</span>
</span></span><span class=line><span class=cl>  <span class=kt>float</span><span class=o>*</span> <span class=n>ptr_b</span> <span class=o>=</span> <span class=k>static_cast</span><span class=o>&lt;</span><span class=kt>float</span><span class=o>*&gt;</span><span class=p>(</span><span class=n>buf_b</span><span class=p>.</span><span class=n>ptr</span><span class=p>);</span>
</span></span><span class=line><span class=cl>  <span class=kt>float</span><span class=o>*</span> <span class=n>ptr_r</span> <span class=o>=</span> <span class=k>static_cast</span><span class=o>&lt;</span><span class=kt>float</span><span class=o>*&gt;</span><span class=p>(</span><span class=n>buf_r</span><span class=p>.</span><span class=n>ptr</span><span class=p>);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>// AVX + OpenMP (canonical loop)
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=cp>#pragma omp parallel for
</span></span></span><span class=line><span class=cl><span class=cp></span>  <span class=k>for</span> <span class=p>(</span><span class=n>size_t</span> <span class=n>i</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=n>i</span> <span class=o>&lt;</span> <span class=n>n8</span><span class=p>;</span> <span class=n>i</span> <span class=o>+=</span> <span class=mi>8</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=n>__m256</span> <span class=n>va</span> <span class=o>=</span> <span class=n>_mm256_loadu_ps</span><span class=p>(</span><span class=n>ptr_a</span> <span class=o>+</span> <span class=n>i</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=n>__m256</span> <span class=n>vb</span> <span class=o>=</span> <span class=n>_mm256_loadu_ps</span><span class=p>(</span><span class=n>ptr_b</span> <span class=o>+</span> <span class=n>i</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=n>__m256</span> <span class=n>vr</span> <span class=o>=</span> <span class=n>_mm256_add_ps</span><span class=p>(</span><span class=n>va</span><span class=p>,</span> <span class=n>vb</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=n>_mm256_storeu_ps</span><span class=p>(</span><span class=n>ptr_r</span> <span class=o>+</span> <span class=n>i</span><span class=p>,</span> <span class=n>vr</span><span class=p>);</span>
</span></span><span class=line><span class=cl>  <span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=k>for</span> <span class=p>(</span><span class=n>size_t</span> <span class=n>i</span> <span class=o>=</span> <span class=n>n8</span><span class=p>;</span> <span class=n>i</span> <span class=o>&lt;</span> <span class=n>n</span><span class=p>;</span> <span class=o>++</span><span class=n>i</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=n>ptr_r</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=o>=</span> <span class=n>ptr_a</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=o>+</span> <span class=n>ptr_b</span><span class=p>[</span><span class=n>i</span><span class=p>];</span>
</span></span><span class=line><span class=cl>  <span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=k>return</span> <span class=n>result</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>PYBIND11_MODULE</span><span class=p>(</span><span class=n>example_cpu</span><span class=p>,</span> <span class=n>m</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>  <span class=n>m</span><span class=p>.</span><span class=n>def</span><span class=p>(</span><span class=s>&#34;add_vectorized&#34;</span><span class=p>,</span> <span class=o>&amp;</span><span class=n>add_vectorized</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s>&#34;Vectorized float addition with SIMD and OpenMP&#34;</span><span class=p>);</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><hr><h2 id=5-cuda-gpu-function>5 CUDA GPU function<a hidden class=anchor aria-hidden=true href=#5-cuda-gpu-function>#</a></h2><p>./example_cuda.cu</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-cpp data-lang=cpp><span class=line><span class=cl><span class=cp>#include</span> <span class=cpf>&lt;cuda_runtime.h&gt;</span><span class=cp>
</span></span></span><span class=line><span class=cl><span class=cp>#include</span> <span class=cpf>&lt;pybind11/numpy.h&gt;</span><span class=cp>
</span></span></span><span class=line><span class=cl><span class=cp>#include</span> <span class=cpf>&lt;pybind11/pybind11.h&gt;</span><span class=cp>
</span></span></span><span class=line><span class=cl><span class=cp></span>
</span></span><span class=line><span class=cl><span class=cp>#include</span> <span class=cpf>&lt;stdexcept&gt;</span><span class=cp>
</span></span></span><span class=line><span class=cl><span class=cp></span>
</span></span><span class=line><span class=cl><span class=k>namespace</span> <span class=n>py</span> <span class=o>=</span> <span class=n>pybind11</span><span class=p>;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>__global__</span> <span class=kt>void</span> <span class=nf>add_kernel</span><span class=p>(</span><span class=k>const</span> <span class=kt>float</span><span class=o>*</span> <span class=n>a</span><span class=p>,</span> <span class=k>const</span> <span class=kt>float</span><span class=o>*</span> <span class=n>b</span><span class=p>,</span> <span class=kt>float</span><span class=o>*</span> <span class=n>out</span><span class=p>,</span> <span class=kt>int</span> <span class=n>n</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>  <span class=kt>int</span> <span class=n>idx</span> <span class=o>=</span> <span class=n>blockIdx</span><span class=p>.</span><span class=n>x</span> <span class=o>*</span> <span class=n>blockDim</span><span class=p>.</span><span class=n>x</span> <span class=o>+</span> <span class=n>threadIdx</span><span class=p>.</span><span class=n>x</span><span class=p>;</span>
</span></span><span class=line><span class=cl>  <span class=k>if</span> <span class=p>(</span><span class=n>idx</span> <span class=o>&lt;</span> <span class=n>n</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=n>out</span><span class=p>[</span><span class=n>idx</span><span class=p>]</span> <span class=o>=</span> <span class=n>a</span><span class=p>[</span><span class=n>idx</span><span class=p>]</span> <span class=o>+</span> <span class=n>b</span><span class=p>[</span><span class=n>idx</span><span class=p>];</span>
</span></span><span class=line><span class=cl>  <span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>py</span><span class=o>::</span><span class=n>array_t</span><span class=o>&lt;</span><span class=kt>float</span><span class=o>&gt;</span> <span class=n>add_cuda</span><span class=p>(</span><span class=n>py</span><span class=o>::</span><span class=n>array_t</span><span class=o>&lt;</span><span class=kt>float</span><span class=o>&gt;</span> <span class=n>a</span><span class=p>,</span> <span class=n>py</span><span class=o>::</span><span class=n>array_t</span><span class=o>&lt;</span><span class=kt>float</span><span class=o>&gt;</span> <span class=n>b</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>  <span class=k>auto</span> <span class=n>buf_a</span> <span class=o>=</span> <span class=n>a</span><span class=p>.</span><span class=n>request</span><span class=p>();</span>
</span></span><span class=line><span class=cl>  <span class=k>auto</span> <span class=n>buf_b</span> <span class=o>=</span> <span class=n>b</span><span class=p>.</span><span class=n>request</span><span class=p>();</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=k>if</span> <span class=p>(</span><span class=n>buf_a</span><span class=p>.</span><span class=n>size</span> <span class=o>!=</span> <span class=n>buf_b</span><span class=p>.</span><span class=n>size</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=k>throw</span> <span class=n>std</span><span class=o>::</span><span class=n>runtime_error</span><span class=p>(</span><span class=s>&#34;Arrays must have the same size&#34;</span><span class=p>);</span>
</span></span><span class=line><span class=cl>  <span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=kt>int</span> <span class=n>n</span> <span class=o>=</span> <span class=k>static_cast</span><span class=o>&lt;</span><span class=kt>int</span><span class=o>&gt;</span><span class=p>(</span><span class=n>buf_a</span><span class=p>.</span><span class=n>size</span><span class=p>);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=kt>float</span><span class=o>*</span> <span class=n>d_a</span> <span class=o>=</span> <span class=k>nullptr</span><span class=p>;</span>
</span></span><span class=line><span class=cl>  <span class=kt>float</span><span class=o>*</span> <span class=n>d_b</span> <span class=o>=</span> <span class=k>nullptr</span><span class=p>;</span>
</span></span><span class=line><span class=cl>  <span class=kt>float</span><span class=o>*</span> <span class=n>d_out</span> <span class=o>=</span> <span class=k>nullptr</span><span class=p>;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=n>cudaMalloc</span><span class=p>(</span><span class=o>&amp;</span><span class=n>d_a</span><span class=p>,</span> <span class=n>n</span> <span class=o>*</span> <span class=k>sizeof</span><span class=p>(</span><span class=kt>float</span><span class=p>));</span>
</span></span><span class=line><span class=cl>  <span class=n>cudaMalloc</span><span class=p>(</span><span class=o>&amp;</span><span class=n>d_b</span><span class=p>,</span> <span class=n>n</span> <span class=o>*</span> <span class=k>sizeof</span><span class=p>(</span><span class=kt>float</span><span class=p>));</span>
</span></span><span class=line><span class=cl>  <span class=n>cudaMalloc</span><span class=p>(</span><span class=o>&amp;</span><span class=n>d_out</span><span class=p>,</span> <span class=n>n</span> <span class=o>*</span> <span class=k>sizeof</span><span class=p>(</span><span class=kt>float</span><span class=p>));</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=n>cudaMemcpy</span><span class=p>(</span><span class=n>d_a</span><span class=p>,</span> <span class=n>buf_a</span><span class=p>.</span><span class=n>ptr</span><span class=p>,</span> <span class=n>n</span> <span class=o>*</span> <span class=k>sizeof</span><span class=p>(</span><span class=kt>float</span><span class=p>),</span> <span class=n>cudaMemcpyHostToDevice</span><span class=p>);</span>
</span></span><span class=line><span class=cl>  <span class=n>cudaMemcpy</span><span class=p>(</span><span class=n>d_b</span><span class=p>,</span> <span class=n>buf_b</span><span class=p>.</span><span class=n>ptr</span><span class=p>,</span> <span class=n>n</span> <span class=o>*</span> <span class=k>sizeof</span><span class=p>(</span><span class=kt>float</span><span class=p>),</span> <span class=n>cudaMemcpyHostToDevice</span><span class=p>);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=kt>int</span> <span class=n>block</span> <span class=o>=</span> <span class=mi>256</span><span class=p>;</span>
</span></span><span class=line><span class=cl>  <span class=kt>int</span> <span class=n>grid</span> <span class=o>=</span> <span class=p>(</span><span class=n>n</span> <span class=o>+</span> <span class=n>block</span> <span class=o>-</span> <span class=mi>1</span><span class=p>)</span> <span class=o>/</span> <span class=n>block</span><span class=p>;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=n>add_kernel</span><span class=o>&lt;&lt;&lt;</span><span class=n>grid</span><span class=p>,</span> <span class=n>block</span><span class=o>&gt;&gt;&gt;</span><span class=p>(</span><span class=n>d_a</span><span class=p>,</span> <span class=n>d_b</span><span class=p>,</span> <span class=n>d_out</span><span class=p>,</span> <span class=n>n</span><span class=p>);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=k>auto</span> <span class=n>result</span> <span class=o>=</span> <span class=n>py</span><span class=o>::</span><span class=n>array_t</span><span class=o>&lt;</span><span class=kt>float</span><span class=o>&gt;</span><span class=p>(</span><span class=n>n</span><span class=p>);</span>
</span></span><span class=line><span class=cl>  <span class=n>cudaMemcpy</span><span class=p>(</span><span class=n>result</span><span class=p>.</span><span class=n>mutable_data</span><span class=p>(),</span> <span class=n>d_out</span><span class=p>,</span> <span class=n>n</span> <span class=o>*</span> <span class=k>sizeof</span><span class=p>(</span><span class=kt>float</span><span class=p>),</span>
</span></span><span class=line><span class=cl>             <span class=n>cudaMemcpyDeviceToHost</span><span class=p>);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=n>cudaFree</span><span class=p>(</span><span class=n>d_a</span><span class=p>);</span>
</span></span><span class=line><span class=cl>  <span class=n>cudaFree</span><span class=p>(</span><span class=n>d_b</span><span class=p>);</span>
</span></span><span class=line><span class=cl>  <span class=n>cudaFree</span><span class=p>(</span><span class=n>d_out</span><span class=p>);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=k>return</span> <span class=n>result</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>PYBIND11_MODULE</span><span class=p>(</span><span class=n>example_cuda</span><span class=p>,</span> <span class=n>m</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>  <span class=n>m</span><span class=p>.</span><span class=n>def</span><span class=p>(</span><span class=s>&#34;add_cuda&#34;</span><span class=p>,</span> <span class=o>&amp;</span><span class=n>add_cuda</span><span class=p>,</span> <span class=s>&#34;Add arrays on GPU using CUDA&#34;</span><span class=p>);</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>Compile with:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>nvcc -O3 --compiler-options <span class=s1>&#39;-fPIC&#39;</span> -shared example_cuda.cu <span class=sb>`</span>python3 -m pybind11 --includes<span class=sb>`</span> -o example/example_cuda.so -lcudart
</span></span></code></pre></div><p>Python sees the <code>.so</code> as a normal module while execution happens on GPU</p><hr><h2 id=6-understanding-so-files-wheels-and-python-abi>6 Understanding .so files, wheels, and Python ABI<a hidden class=anchor aria-hidden=true href=#6-understanding-so-files-wheels-and-python-abi>#</a></h2><p>Python ABI means <strong>Application Binary Interface</strong>. The chain is:</p><pre tabindex=0><code>Python → CPython ABI → .so → C++ functions
</code></pre><p>Pybind11 leverages this chain. Using setuptools we can compile C++ code into a <code>.so</code> file that Python can load dynamically. A <code>.so</code> file is not a standalone program it is a <strong>live binary module</strong>:</p><ul><li><code>.exe</code> standalone executable</li><li><code>.a</code> static library (copied in at compile time)</li><li><code>.so</code> shared library loaded at runtime</li></ul><p>Alternatives:</p><ul><li>Linux <code>.so</code></li><li>macOS <code>.dylib</code></li><li>Windows <code>.dll</code></li></ul><h3 id=anatomy-of-a-so-file>Anatomy of a <code>.so</code> file<a hidden class=anchor aria-hidden=true href=#anatomy-of-a-so-file>#</a></h3><p>A <code>.so</code> is an ELF file containing:</p><ol><li><p>Machine code - CPU instructions not bytecode</p></li><li><p>Symbol table - exported functions and variables for linking</p></li><li><p>Relocation info - how addresses are fixed at load time</p></li><li><p>Dynamic section - dependencies on other <code>.so</code> files</p></li><li><p>Sections:</p><ul><li><code>.text</code> executable code</li><li><code>.data</code> initialized globals</li><li><code>.bss</code> uninitialized globals</li><li><code>.rodata</code> constants</li></ul></li></ol><h3 id=runtime-usage>Runtime usage<a hidden class=anchor aria-hidden=true href=#runtime-usage>#</a></h3><ol><li>Program starts</li><li>Dynamic linker (<code>ld-linux.so</code>) loads <code>.so</code></li><li>Symbols resolved</li><li>Code mapped into memory</li><li>Functions callable like normal code</li></ol><p>Important note: <code>.so</code> files <strong>cannot be moved across CPU architectures</strong></p><h3 id=wheels>Wheels<a hidden class=anchor aria-hidden=true href=#wheels>#</a></h3><p>Wheels (<code>.whl</code>) are <strong>Python distribution packages</strong> that can include <code>.so</code> modules. They allow precompiled code to be installed with pip, avoiding the need for users to have a compiler:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>python3 -m build
</span></span><span class=line><span class=cl>pip install dist/example-0.1.0-*.whl --force-reinstall
</span></span></code></pre></div><p>Key difference: <code>.so</code> is the <strong>runtime artifact</strong>. Wheel is the <strong>distribution format</strong> containing <code>.so</code> files, metadata, and Python package structure.</p><hr><h2 id=7-setup-script>7 Setup script<a hidden class=anchor aria-hidden=true href=#7-setup-script>#</a></h2><p>setup.py</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>setuptools</span> <span class=kn>import</span> <span class=n>setup</span><span class=p>,</span> <span class=n>Extension</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>pybind11</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>os</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>cpu_ext</span> <span class=o>=</span> <span class=n>Extension</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>name</span><span class=o>=</span><span class=s2>&#34;example.example_cpu&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>sources</span><span class=o>=</span><span class=p>[</span><span class=s2>&#34;example_cpu.cpp&#34;</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=n>include_dirs</span><span class=o>=</span><span class=p>[</span><span class=n>pybind11</span><span class=o>.</span><span class=n>get_include</span><span class=p>()],</span>
</span></span><span class=line><span class=cl>    <span class=n>extra_compile_args</span><span class=o>=</span><span class=p>[</span><span class=s2>&#34;-O3&#34;</span><span class=p>,</span> <span class=s2>&#34;-march=native&#34;</span><span class=p>,</span> <span class=s2>&#34;-fopenmp&#34;</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=n>extra_link_args</span><span class=o>=</span><span class=p>[</span><span class=s2>&#34;-fopenmp&#34;</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=n>language</span><span class=o>=</span><span class=s2>&#34;c++&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>cuda_so</span> <span class=o>=</span> <span class=n>os</span><span class=o>.</span><span class=n>path</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=s2>&#34;example&#34;</span><span class=p>,</span> <span class=s2>&#34;example_cuda.so&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=k>if</span> <span class=ow>not</span> <span class=n>os</span><span class=o>.</span><span class=n>path</span><span class=o>.</span><span class=n>exists</span><span class=p>(</span><span class=n>cuda_so</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>raise</span> <span class=ne>RuntimeError</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;example_cuda.so not found.</span><span class=se>\n</span><span class=s2>&#34;</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;Build it first with nvcc before running setup.py.&#34;</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>setup</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>name</span><span class=o>=</span><span class=s2>&#34;example&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>version</span><span class=o>=</span><span class=s2>&#34;0.1.0&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>packages</span><span class=o>=</span><span class=p>[</span><span class=s2>&#34;example&#34;</span><span class=p>],</span>
</span></span><span class=line><span class=cl>     <span class=n>package_data</span><span class=o>=</span><span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;example&#34;</span><span class=p>:</span> <span class=p>[</span><span class=s2>&#34;example_cuda.so&#34;</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=p>},</span>
</span></span><span class=line><span class=cl>    <span class=n>ext_modules</span><span class=o>=</span><span class=p>[</span><span class=n>cpu_ext</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=n>zip_safe</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span></code></pre></div><hr><h2 id=8-demo-and-benchmark>8 Demo and Benchmark<a hidden class=anchor aria-hidden=true href=#8-demo-and-benchmark>#</a></h2><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>example</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>time</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># -----------------------------</span>
</span></span><span class=line><span class=cl><span class=c1># Config</span>
</span></span><span class=line><span class=cl><span class=c1># -----------------------------</span>
</span></span><span class=line><span class=cl><span class=n>N</span> <span class=o>=</span> <span class=mi>1_000_000_000</span>
</span></span><span class=line><span class=cl><span class=n>REPS</span> <span class=o>=</span> <span class=mi>10</span>
</span></span><span class=line><span class=cl><span class=n>PRINT_N</span> <span class=o>=</span> <span class=mi>10</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># -----------------------------</span>
</span></span><span class=line><span class=cl><span class=c1># Prepare arrays</span>
</span></span><span class=line><span class=cl><span class=c1># -----------------------------</span>
</span></span><span class=line><span class=cl><span class=n>a</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>rand</span><span class=p>(</span><span class=n>N</span><span class=p>)</span><span class=o>.</span><span class=n>astype</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>float32</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>b</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>rand</span><span class=p>(</span><span class=n>N</span><span class=p>)</span><span class=o>.</span><span class=n>astype</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>float32</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># -----------------------------</span>
</span></span><span class=line><span class=cl><span class=c1># CPU benchmark</span>
</span></span><span class=line><span class=cl><span class=c1># -----------------------------</span>
</span></span><span class=line><span class=cl><span class=n>cpu_times</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>_</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>REPS</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>start</span> <span class=o>=</span> <span class=n>time</span><span class=o>.</span><span class=n>time</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>c_cpu</span> <span class=o>=</span> <span class=n>example</span><span class=o>.</span><span class=n>add_vectorized</span><span class=p>(</span><span class=n>a</span><span class=p>,</span> <span class=n>b</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>end</span> <span class=o>=</span> <span class=n>time</span><span class=o>.</span><span class=n>time</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>cpu_times</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>end</span> <span class=o>-</span> <span class=n>start</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>avg_cpu</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>cpu_times</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;CPU first </span><span class=si>{</span><span class=n>PRINT_N</span><span class=si>}</span><span class=s2> elements: </span><span class=si>{</span><span class=n>c_cpu</span><span class=p>[:</span><span class=n>PRINT_N</span><span class=p>]</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;CPU total time: </span><span class=si>{</span><span class=n>avg_cpu</span><span class=si>:</span><span class=s2>.6f</span><span class=si>}</span><span class=s2>s, per element: </span><span class=si>{</span><span class=n>avg_cpu</span><span class=o>/</span><span class=n>N</span><span class=o>*</span><span class=mf>1e9</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2> ns/element&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># -----------------------------</span>
</span></span><span class=line><span class=cl><span class=c1># GPU benchmark (total)</span>
</span></span><span class=line><span class=cl><span class=c1># -----------------------------</span>
</span></span><span class=line><span class=cl><span class=c1># Warm-up</span>
</span></span><span class=line><span class=cl><span class=n>example</span><span class=o>.</span><span class=n>add_cuda</span><span class=p>(</span><span class=n>a</span><span class=p>,</span> <span class=n>b</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>gpu_times</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>_</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>REPS</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>start</span> <span class=o>=</span> <span class=n>time</span><span class=o>.</span><span class=n>time</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>c_gpu</span> <span class=o>=</span> <span class=n>example</span><span class=o>.</span><span class=n>add_cuda</span><span class=p>(</span><span class=n>a</span><span class=p>,</span> <span class=n>b</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>end</span> <span class=o>=</span> <span class=n>time</span><span class=o>.</span><span class=n>time</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>gpu_times</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>end</span> <span class=o>-</span> <span class=n>start</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>avg_gpu_total</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>gpu_times</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;GPU first </span><span class=si>{</span><span class=n>PRINT_N</span><span class=si>}</span><span class=s2> elements: </span><span class=si>{</span><span class=n>c_gpu</span><span class=p>[:</span><span class=n>PRINT_N</span><span class=p>]</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;GPU total time: </span><span class=si>{</span><span class=n>avg_gpu_total</span><span class=si>:</span><span class=s2>.6f</span><span class=si>}</span><span class=s2>s, per element: </span><span class=si>{</span><span class=n>avg_gpu_total</span><span class=o>/</span><span class=n>N</span><span class=o>*</span><span class=mf>1e9</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2> ns/element&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># -----------------------------</span>
</span></span><span class=line><span class=cl><span class=c1># Verify correctness</span>
</span></span><span class=line><span class=cl><span class=c1># -----------------------------</span>
</span></span><span class=line><span class=cl><span class=k>if</span> <span class=n>np</span><span class=o>.</span><span class=n>allclose</span><span class=p>(</span><span class=n>c_cpu</span><span class=p>,</span> <span class=n>c_gpu</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;CPU and GPU results match!&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;CPU and GPU results do not match!&#34;</span><span class=p>)</span>
</span></span></code></pre></div><p><em>GPU overhead is significant for small arrays because of <strong>memory transfer latency</strong>. With larger arrays, GPU naturally outperforms due to massive parallelization.</em></p><figure><img loading=lazy src=/images/pybind_cuda_cpu_stupid_benchmark.jpg><figcaption><p>Benchmark results at 1B floats for cpu/gpu simple examples in pybind.</p></figcaption></figure><hr><h2 id=9-makefile--pyprojecttoml>9 Makefile & Pyproject.toml<a hidden class=anchor aria-hidden=true href=#9-makefile--pyprojecttoml>#</a></h2><p><strong>Makefile</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-make data-lang=make><span class=line><span class=cl><span class=nf>all</span><span class=o>:</span> <span class=n>run</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nf>example/example_cuda.so</span><span class=o>:</span> <span class=n>example_cuda</span>.<span class=n>cu</span>
</span></span><span class=line><span class=cl>	mkdir -p example
</span></span><span class=line><span class=cl>	nvcc -O3 --compiler-options <span class=s1>&#39;-fPIC&#39;</span> -shared example_cuda.cu <span class=sb>`</span>python3 -m pybind11 --includes<span class=sb>`</span> -o example/example_cuda.so -lcudart
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nf>example/__init__.py</span><span class=o>:</span> <span class=n>example</span>/<span class=n>example_cuda</span>.<span class=n>so</span>
</span></span><span class=line><span class=cl>	<span class=nb>echo</span> <span class=s2>&#34;from .example_cuda import *&#34;</span> &gt; example/__init__.py
</span></span><span class=line><span class=cl>	<span class=nb>echo</span> <span class=s2>&#34;from .example_cpu import *&#34;</span> &gt;&gt; example/__init__.py
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nf>wheel</span><span class=o>:</span> <span class=n>example</span>/<span class=n>__init__</span>.<span class=n>py</span>
</span></span><span class=line><span class=cl>	python3 -m build
</span></span><span class=line><span class=cl>	mv ./example ./example_src
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nf>install</span><span class=o>:</span> <span class=n>wheel</span>
</span></span><span class=line><span class=cl>	pip install dist/example-0.1.0-*.whl --force-reinstall
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nf>run</span><span class=o>:</span> <span class=n>install</span>
</span></span><span class=line><span class=cl>	python3 ./benchmark.py
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nf>clean</span><span class=o>:</span>
</span></span><span class=line><span class=cl>	pip uninstall example -y
</span></span><span class=line><span class=cl>	rm -rf build dist example.egg-info example-0.1.0 example
</span></span></code></pre></div><p><strong>pyproject.toml</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-toml data-lang=toml><span class=line><span class=cl><span class=p>[</span><span class=nx>build-system</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=nx>requires</span> <span class=p>=</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;setuptools&gt;=64&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;wheel&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;pybind11&gt;=2.10&#34;</span>
</span></span><span class=line><span class=cl><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=nx>build-backend</span> <span class=p>=</span> <span class=s2>&#34;setuptools.build_meta&#34;</span>
</span></span></code></pre></div><p>This allows building the package with <code>python3 build</code> and distributing as a wheel.</p><hr><h2 id=10-python-package-lifecycle--dependency-management>10 Python Package Lifecycle & Dependency Management<a hidden class=anchor aria-hidden=true href=#10-python-package-lifecycle--dependency-management>#</a></h2><p>Understanding how Python modules, packages, compiled extensions, and dependencies interact is crucial when building libraries like your own NumPy clone. Here’s a detailed breakdown:</p><h3 id=101-modules-and-packages>10.1 Modules and Packages<a hidden class=anchor aria-hidden=true href=#101-modules-and-packages>#</a></h3><ul><li><strong>Module</strong>: a single <code>.py</code> file containing Python code-functions, classes, constants-that can be imported. Example:</li></ul><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># utils.py</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>add</span><span class=p>(</span><span class=n>a</span><span class=p>,</span> <span class=n>b</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>a</span> <span class=o>+</span> <span class=n>b</span>
</span></span></code></pre></div><ul><li><strong>Package</strong>: a directory with an <code>__init__.py</code> file (even if empty) that tells Python “this is a package.” Packages can contain multiple modules and sub-packages, creating a hierarchical structure:</li></ul><pre tabindex=0><code>mypackage/
├── __init__.py
├── utils.py
└── subpackage/
    ├── __init__.py
    └── math_ops.py
</code></pre><ul><li><p>Packages may also include:</p><ul><li><strong>Compiled extensions</strong> (<code>.so</code> on Linux, <code>.pyd</code> on Windows), typically generated via <strong>pybind11</strong> or <strong>Cython</strong>.</li><li><strong>Data files</strong> (images, JSON, CSV, etc.)</li><li><strong>Metadata files</strong> (<code>setup.py</code>, <code>pyproject.toml</code>, <code>MANIFEST.in</code>) describing the package, version, dependencies, and entry points.</li></ul></li></ul><hr><h3 id=102-installation-process>10.2 Installation Process<a hidden class=anchor aria-hidden=true href=#102-installation-process>#</a></h3><p>When you install a package locally or via PyPI:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>pip install ./mypackage
</span></span></code></pre></div><ol><li><strong>Metadata parsing</strong>: Pip reads <code>setup.py</code> or <code>pyproject.toml</code> to discover package info and dependencies.</li><li><strong>Dependency resolution</strong>: Pip determines which other packages are needed, including versions.</li><li><strong>Compilation of extensions</strong>: Any <code>.cpp</code> or <code>.cu</code> files are compiled into <code>.so</code>/<code>.pyd</code> using the system compiler.</li><li><strong>Copying files</strong>: Python code, compiled binaries, and package data are copied into the <code>site-packages</code> directory of your environment.</li><li><strong>Isolation via virtual environments</strong>: If you’re inside a <code>venv</code>, this installation is isolated from the system Python. This allows multiple versions of the same package in different projects without conflict.</li><li><strong>Metadata storage</strong>: Pip generates <code>.dist-info</code> folders containing package metadata, dependencies, and file records for uninstallation or introspection.</li></ol><hr><h3 id=103-wheels-and-distribution>10.3 Wheels and Distribution<a hidden class=anchor aria-hidden=true href=#103-wheels-and-distribution>#</a></h3><ul><li><strong>Wheel (<code>.whl</code>)</strong>: a standardized binary distribution format for Python. Wheels can include precompiled extensions so users <strong>don’t need a compiler</strong>.</li><li>Platform-specific if compiled extensions exist; pure Python wheels work across all platforms.</li><li><strong>Source distribution (<code>.tar.gz</code>)</strong> contains the raw Python/C++ source and requires compilation at install time.</li><li>Uploading:</li></ul><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>twine upload dist/mypackage-0.1.0-py3-none-any.whl
</span></span></code></pre></div><ul><li>Users can then install via:</li></ul><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>pip install mypackage
</span></span></code></pre></div><ul><li>The wheel contains everything pip needs: Python code, compiled binaries, metadata, and optional console scripts.</li></ul><hr><h3 id=104-python-abi-and-compiled-extensions>10.4 Python ABI and Compiled Extensions<a hidden class=anchor aria-hidden=true href=#104-python-abi-and-compiled-extensions>#</a></h3><ul><li><p><strong>Python ABI (Application Binary Interface)</strong> defines how compiled extensions (.so or .pyd) interact with the Python interpreter.</p></li><li><p>Pybind11 wraps C++ or CUDA code and exposes it through the CPython ABI so that Python can <strong>dynamically load functions at runtime</strong>.</p></li><li><p>Life cycle for compiled extensions:</p><ol><li><code>.so</code> or <code>.pyd</code> is compiled.</li><li>Python imports the module.</li><li>The system loader dynamically maps the machine code into memory.</li><li>Python calls functions in the extension as if they were regular Python functions.</li></ol></li><li><p><code>.so</code> files <strong>cannot be moved across CPU architectures</strong>; they must be recompiled for each target CPU.</p></li></ul><hr><h3 id=105-dependency-management>10.5 Dependency Management<a hidden class=anchor aria-hidden=true href=#105-dependency-management>#</a></h3><p>Modern Python projects often include external dependencies. Dependencies can be:</p><ul><li><strong>PyPI packages</strong> (e.g., numpy, scipy)</li><li><strong>Git repositories</strong> (private or public)</li></ul><p>Example in <code>pyproject.toml</code> or <code>requirements.txt</code>:</p><pre tabindex=0><code>git+https://github.com/username/mylib.git@v1.2.3#egg=mylib
</code></pre><ul><li><p>When pip installs this dependency:</p><ul><li>It fetches the repository.</li><li>Checks out the specified commit, branch, or tag.</li><li>Installs it alongside standard PyPI packages.</li></ul></li><li><p>Pip itself <strong>does not resolve Git versions from lock files</strong> (like <code>uv.lock</code>); it only installs the URL you provide.</p></li><li><p>Tools like <strong>Poetry</strong> or <strong>pip-tools</strong> sit on top of pip:</p><ul><li>They generate <strong>lock files</strong> (<code>poetry.lock</code> or <code>requirements.txt</code>) that pin exact versions and commits.</li><li>They ensure reproducible installations across environments.</li></ul></li><li><p>Version specifiers:</p><ul><li><code>==1.2.3</code> → exact version</li><li><code>>=1.2.0,&lt;2.0.0</code> → compatible range</li><li><code>~=1.2.3</code> → compatible with 1.2.x patches</li></ul></li></ul><p>Unlike Node.js/npm, Python does <strong>not deduplicate versions automatically</strong>; multiple versions may coexist in <code>site-packages</code>. Tools like Poetry or uv resolve versions into a deterministic environment.</p><hr><h3 id=106-full-lifecycle>10.6 Full Lifecycle<a hidden class=anchor aria-hidden=true href=#106-full-lifecycle>#</a></h3><ol><li><strong>Develop</strong> your module/package.</li><li><strong>Structure</strong> it with <code>__init__.py</code>, metadata, optional compiled extensions, and data files.</li><li><strong>Test locally</strong> in a virtual environment.</li><li><strong>Build</strong> sdist or wheel.</li><li><strong>Publish</strong> to PyPI or private repository.</li><li><strong>Install</strong> in another environment with pip.</li><li>Python handles <strong>module resolution, dynamic loading</strong>, and <strong>dependency management</strong>.</li></ol><p><em>Extra notes</em>:</p><ul><li>Packages can include <strong>console scripts</strong> (entry points), type stubs, and runtime-accessible data.</li><li>Compiled extensions bridge Python with high-performance C++/CUDA code.</li><li>With proper packaging, users can run your library without a compiler, achieving both <strong>ease of installation</strong> and <strong>high performance</strong>.</li></ul><hr></div><footer class=post-footer><ul class=post-tags><li><a href=http://localhost:1313/tags/python/>Python</a></li><li><a href=http://localhost:1313/tags/numpy/>Numpy</a></li><li><a href=http://localhost:1313/tags/pybind/>Pybind</a></li><li><a href=http://localhost:1313/tags/cpp/>Cpp</a></li><li><a href=http://localhost:1313/tags/simd/>SIMD</a></li><li><a href=http://localhost:1313/tags/cuda/>CUDA</a></li><li><a href=http://localhost:1313/tags/openmp/>OpenMP</a></li><li><a href=http://localhost:1313/tags/scientific-computing/>Scientific Computing</a></li><li><a href=http://localhost:1313/tags/extensions/>Extensions</a></li><li><a href=http://localhost:1313/tags/packaging/>Packaging</a></li><li><a href=http://localhost:1313/tags/abi/>Abi</a></li></ul><nav class=paginav><a class=next href=http://localhost:1313/posts/memory-of-forgotten/><span class=title>Next »</span><br><span>NOTES: Memory of Forgotten</span></a></nav></footer></article></main><footer class=footer><span>&copy; 2026 <a href=http://localhost:1313/>T|A</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>