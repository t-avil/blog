<!doctype html><html lang=en dir=auto><head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>NOTES: VMing the Containers - The Latency-Availability Tradeoff | T|A</title><meta name=keywords content="notes,virtualization,containers,docker,distributed-systems,kubernetes"><meta name=description content="Exploring the tradeoffs between containers and virtual machines, from trap-and-emulate to modern orchestration systems. Spoiler: they're both here to stay."><meta name=author content="Me"><link rel=canonical href=https://canonical.url/to/page><link crossorigin=anonymous href=/assets/css/stylesheet.3f7ba6a00d316a1658af1e52b60f5592bfd3f63e1683217d447958625c9fec2a.css integrity="sha256-P3umoA0xahZYrx5Stg9Vkr/T9j4WgyF9RHlYYlyf7Co=" rel="preload stylesheet" as=style><link rel=icon href=http://localhost:1313/favicon.ico><link rel=icon type=image/png sizes=16x16 href=http://localhost:1313/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=http://localhost:1313/favicon-32x32.png><link rel=apple-touch-icon href=http://localhost:1313/apple-touch-icon.png><link rel=mask-icon href=http://localhost:1313/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=http://localhost:1313/posts/vming-containers/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:url" content="http://localhost:1313/posts/vming-containers/"><meta property="og:site_name" content="T|A"><meta property="og:title" content="NOTES: VMing the Containers - The Latency-Availability Tradeoff"><meta property="og:description" content="Exploring the tradeoffs between containers and virtual machines, from trap-and-emulate to modern orchestration systems. Spoiler: they're both here to stay."><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-10-05T14:30:00-07:00"><meta property="article:modified_time" content="2025-10-05T14:30:00-07:00"><meta property="article:tag" content="Notes"><meta property="article:tag" content="Virtualization"><meta property="article:tag" content="Containers"><meta property="article:tag" content="Docker"><meta property="article:tag" content="Distributed-Systems"><meta property="article:tag" content="Kubernetes"><meta property="og:image" content="http://localhost:1313/images/papermod-cover.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="http://localhost:1313/images/papermod-cover.png"><meta name=twitter:title content="NOTES: VMing the Containers - The Latency-Availability Tradeoff"><meta name=twitter:description content="Exploring the tradeoffs between containers and virtual machines, from trap-and-emulate to modern orchestration systems. Spoiler: they're both here to stay."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"http://localhost:1313/posts/"},{"@type":"ListItem","position":2,"name":"NOTES: VMing the Containers - The Latency-Availability Tradeoff","item":"http://localhost:1313/posts/vming-containers/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"NOTES: VMing the Containers - The Latency-Availability Tradeoff","name":"NOTES: VMing the Containers - The Latency-Availability Tradeoff","description":"Exploring the tradeoffs between containers and virtual machines, from trap-and-emulate to modern orchestration systems. Spoiler: they're both here to stay.","keywords":["notes","virtualization","containers","docker","distributed-systems","kubernetes"],"articleBody":"Before we dive into containers vs VMs, let’s talk about what virtualization actually is. If you’re coming from an OOP background, think of virtualization as the ultimate facade pattern: you’re presenting a clean interface (a “virtual machine”) that hides the messy reality underneath (the actual hardware and hypervisor).\nThere are three main levels of virtualization, each with different tradeoffs:\nTrap-and-emulate: The classic approach where privileged instructions from the guest OS “trap” into the hypervisor, which then emulates them. This is what early VMware and QEMU did in software mode.\nParavirtualization: The guest OS knows it’s virtualized and makes explicit calls to the hypervisor instead of using privileged instructions. Xen pioneered this approach, and it’s more efficient than pure trap-and-emulate but requires modifying the guest OS.\nHardware-assisted virtualization: Intel VT-x and AMD-V added CPU extensions that let hypervisors run guest OSes at native speed without software tricks. This is what modern VMs use under the hood.\nNow, with that context in mind, let’s talk about the container vs VM debate.\nThe Great Debate There’s no clear winner between virtualization and containers. If one of them were clearly worse, we wouldn’t still be studying both.\nIn my opinion, the real tradeoff here is between latency and availability.\nHere I will be speaking about Docker as I am most versed in it. If we imagine a gradient with containers on one side and virtual machines (VMs) on the other, the key difference lies in how the state of the system is managed. For example, real VMs are abstracted enough to capture the entire state of the guest OS. This allows for pausing, checkpointing, kernel upgrades, and migration. On the other hand, container runtimes like Docker (runc or any variant that suppresses the shim API) don’t even support migration and barely support checkpointing. The tradeoff in performance is significant tho. As shown in Container-based Operating System Virtualization: A Scalable, High-performance Alternative to Hypervisors by Stephen Soltesz et al. (EuroSys 2007), the overhead in containers is almost 2x better than hypervisors for many workloads.\nThat said, the paper seems a bit outdated when it talks about containers’ security, networking, and isolation issues, as Docker has addressed most of these. The paper outlines several limitations in container-based operating systems (COS) like Linux-VServer, Virtuozzo, and Solaris Zones, including issues with fault, resource, and security isolation. Containers such as VServer offer limited fault isolation, where a shared kernel can result in a system-wide failure if a fault occurs within one container. Additionally, resource isolation is not foolproof, leading to “cross-talk” between containers that can cause performance inefficiencies, especially when scaling. Security isolation is also weak, as containers share system resources like the PID space, which undermines the strict isolation provided by hypervisors. Networking issues arise from VServer’s inability to fully virtualize the network stack, limiting its ability to configure independent network settings. Finally VServer lacks support for live migration and seamless kernel updates.\nDocker’s Modern Improvements I believe Docker has addressed these limitations. To enhance fault isolation, Docker uses Linux kernel features like namespaces (as far as I know kernels got big upgrades since VServer times - mentioned in paper) and control groups (cgroups). I think the biggest upgrade was that namespaces that now ensure that each container operates in its isolated environment, preventing faults from propagating between containers, while cgroups allocate and limit resource usage. For improved security, Docker employs features such as Enhanced Container Isolation (ECI), which isolates containers at the user namespace level and integrates seccomp profiles and AppArmor to restrict system calls. Docker also enables rootless containers, reducing the security risks associated with privileged access.\nIn terms of networking, Docker provides network namespaces, allowing containers to have their own isolated network stack, complete with independent IP addresses and routing tables. This prevents cross-container network interference. Docker also supports flexible kernel configurations and runtime environments, offering improved container migration capabilities through image spec. This is crucial for kernel updates and system maintenance, minimizing downtime (though rebuilding from the image is still required). Additionally, it’s possible to switch to a different runtime, like Sysbox (instead of runc) for added security.\nDocker has found a second dimension to the gradient tradeoff. It detaches the container’s state, meaning that if a container is restarted, its state is effectively lost. However, this allows containers to be packaged into images that can be easily transferred and redeployed on different hosts.\nImages vs Snapshots Another key point is the idea of images versus snapshots. Docker uses standardized, declarative images to configure environments, while VMs typically rely on snapshotting. In a VM, the entire system is configured starting from a bare minimum and hopes to preserve the state. The question then becomes: which is faster for app recovery - bootstrapping a VM from a checkpoint on a new machine, or letting a container orchestrator recognize the dead container and restart it elsewhere? Even if they were tied, the argument is that VM checkpoints preserve the state, but the latency cost is high. Docker’s persistent volumes allow for state preservation in a serialized way, managed through the application’s business logic layer.\nDo We Actually Need Full Isolation? Now, the real question is: do we actually need hardware emulation or total isolation? Data centers absolutely need these for hard isolation requirements and to emulate a variety of hardware configurations. But for most developers, “secure enough” isolation within a homogeneous stack is sufficient. The largest system I’ve seen had 250 images, which could translate into roughly 3000 containers. Given that an average server has fewer than 50 cores, this would require about 60 machines, which is easily achievable with hyperscale providers like AWS hosting hundreds of thousands of servers in one datacenter.\nSo, my point is: they’re two different tools. Modern containers, with advances in orchestration and performance, cover most use cases. For example, I’ve seen containers boot up in a Kubernetes cluster in under 30ms. VMs, however, are about ensuring compatibility with legacy systems. Whether you need to run Apple1-focused software or Nintendo games, VMs give you the ability to do that while maintaining the state - something crucial probably for some scientific computations.\nThere’s also a middle ground between these two extremes, like KVM, which allows for VM-like workloads to run inside containers. Managing all of these depending on needs is the future. As documented in AWS’s migration history, AWS used Xen for most of the time, then migrated to proprietary AWS Nitro and now even running some nodes on Firecracker microVM which seems to be built on KVM - all of which were mostly probably used as a base layer to host docker images which itself does run a lightweight VM whenever there is a host mismatch.\nClosing Thoughts Having said all of that - the real tradeoff here is between latency (containers are fast) and availability (as heavy VMs can easily checkpoint and migrate) but mostly these 2 techniques will be stacked on each other in practice and it is worth understanding both. The future isn’t about choosing one or the other - it’s about knowing when to use which tool, and increasingly, how to use them together in hybrid architectures that give us the best of both worlds.\n","wordCount":"1198","inLanguage":"en","image":"http://localhost:1313/images/papermod-cover.png","datePublished":"2025-10-05T14:30:00-07:00","dateModified":"2025-10-05T14:30:00-07:00","author":{"@type":"Person","name":"Me"},"mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:1313/posts/vming-containers/"},"publisher":{"@type":"Organization","name":"T|A","logo":{"@type":"ImageObject","url":"http://localhost:1313/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=http://localhost:1313/ accesskey=h title="T|A (Alt + H)">T|A</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=http://localhost:1313/about title=About><span>About</span></a></li><li><a href=http://localhost:1313/chronicles title=Chronicles><span>Chronicles</span></a></li><li><a href=http://localhost:1313/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=http://localhost:1313/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://github.com/t-avil title=Github><span>Github</span>&nbsp;
<svg fill="none" shape-rendering="geometricPrecision" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=http://localhost:1313/>Home</a>&nbsp;»&nbsp;<a href=http://localhost:1313/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">NOTES: VMing the Containers - The Latency-Availability Tradeoff</h1><div class=post-description>Exploring the tradeoffs between containers and virtual machines, from trap-and-emulate to modern orchestration systems. Spoiler: they're both here to stay.</div><div class=post-meta><span title='2025-10-05 14:30:00 -0700 PDT'>October 5, 2025</span>&nbsp;·&nbsp;6 min&nbsp;·&nbsp;1198 words&nbsp;·&nbsp;Me&nbsp;|&nbsp;<a href=https://github.com/t-avil/blog/tree/main/content/posts/vming-containers.md rel="noopener noreferrer edit" target=_blank>Suggest Changes</a></div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><nav id=TableOfContents><ul><li><a href=#the-great-debate>The Great Debate</a></li><li><a href=#dockers-modern-improvements>Docker&rsquo;s Modern Improvements</a></li><li><a href=#images-vs-snapshots>Images vs Snapshots</a></li><li><a href=#do-we-actually-need-full-isolation>Do We Actually Need Full Isolation?</a></li><li><a href=#closing-thoughts>Closing Thoughts</a></li></ul></nav></div></details></div><div class=post-content><p>Before we dive into containers vs VMs, let&rsquo;s talk about what virtualization actually <em>is</em>. If you&rsquo;re coming from an OOP background, think of virtualization as the ultimate facade pattern: you&rsquo;re presenting a clean interface (a &ldquo;virtual machine&rdquo;) that hides the messy reality underneath (the actual hardware and hypervisor).</p><p>There are three main levels of virtualization, each with different tradeoffs:</p><ol><li><p><strong>Trap-and-emulate</strong>: The classic approach where privileged instructions from the guest OS &ldquo;trap&rdquo; into the hypervisor, which then emulates them. This is what early VMware and QEMU did in software mode.</p></li><li><p><strong>Paravirtualization</strong>: The guest OS knows it&rsquo;s virtualized and makes explicit calls to the hypervisor instead of using privileged instructions. Xen pioneered this approach, and it&rsquo;s more efficient than pure trap-and-emulate but requires modifying the guest OS.</p></li><li><p><strong>Hardware-assisted virtualization</strong>: Intel VT-x and AMD-V added CPU extensions that let hypervisors run guest OSes at native speed without software tricks. This is what modern VMs use under the hood.</p></li></ol><p>Now, with that context in mind, let&rsquo;s talk about the container vs VM debate.</p><hr><h2 id=the-great-debate>The Great Debate<a hidden class=anchor aria-hidden=true href=#the-great-debate>#</a></h2><p>There&rsquo;s no clear winner between virtualization and containers. If one of them were clearly worse, we wouldn&rsquo;t still be studying both.</p><p>In my opinion, the real tradeoff here is between latency and availability.</p><p>Here I will be speaking about Docker as I am most versed in it. If we imagine a gradient with containers on one side and virtual machines (VMs) on the other, the key difference lies in how the state of the system is managed. For example, real VMs are abstracted enough to capture the entire state of the guest OS. This allows for pausing, checkpointing, kernel upgrades, and migration. On the other hand, container runtimes like Docker (runc or any variant that suppresses the shim API) don&rsquo;t even support migration and barely support checkpointing. The tradeoff in performance is significant tho. As shown in <a href=https://dl.acm.org/doi/10.1145/1272996.1273025><em>Container-based Operating System Virtualization: A Scalable, High-performance Alternative to Hypervisors</em></a> by Stephen Soltesz et al. (EuroSys 2007), the overhead in containers is almost 2x better than hypervisors for many workloads.</p><p>That said, the paper seems a bit outdated when it talks about containers&rsquo; security, networking, and isolation issues, as Docker has addressed most of these. The paper outlines several limitations in container-based operating systems (COS) like Linux-VServer, Virtuozzo, and Solaris Zones, including issues with fault, resource, and security isolation. Containers such as VServer offer limited fault isolation, where a shared kernel can result in a system-wide failure if a fault occurs within one container. Additionally, resource isolation is not foolproof, leading to &ldquo;cross-talk&rdquo; between containers that can cause performance inefficiencies, especially when scaling. Security isolation is also weak, as containers share system resources like the PID space, which undermines the strict isolation provided by hypervisors. Networking issues arise from VServer&rsquo;s inability to fully virtualize the network stack, limiting its ability to configure independent network settings. Finally VServer lacks support for live migration and seamless kernel updates.</p><hr><h2 id=dockers-modern-improvements>Docker&rsquo;s Modern Improvements<a hidden class=anchor aria-hidden=true href=#dockers-modern-improvements>#</a></h2><p>I believe Docker has addressed these limitations. To enhance fault isolation, Docker uses Linux kernel features like <a href=https://docs.docker.com/engine/security/>namespaces</a> (as far as I know kernels got big upgrades since VServer times - mentioned in paper) and <a href=https://docs.docker.com/engine/security/>control groups (cgroups)</a>. I think the biggest upgrade was that namespaces that now ensure that each container operates in its isolated environment, preventing faults from propagating between containers, while cgroups allocate and limit resource usage. For improved security, Docker employs features such as Enhanced Container Isolation (ECI), which isolates containers at the user namespace level and integrates <a href=https://docs.docker.com/engine/security/seccomp/>seccomp profiles</a> and <a href=https://docs.docker.com/engine/security/apparmor/>AppArmor</a> to restrict system calls. Docker also enables <a href=https://docs.docker.com/engine/security/rootless/>rootless containers</a>, reducing the security risks associated with privileged access.</p><p>In terms of networking, Docker provides network namespaces, allowing containers to have their own isolated network stack, complete with independent IP addresses and routing tables. This prevents cross-container network interference. Docker also supports flexible kernel configurations and runtime environments, offering improved container migration capabilities through image spec. This is crucial for kernel updates and system maintenance, minimizing downtime (though rebuilding from the image is still required). Additionally, it&rsquo;s possible to switch to a different runtime, like Sysbox (instead of runc) for added security.</p><p>Docker has found a second dimension to the gradient tradeoff. It detaches the container&rsquo;s state, meaning that if a container is restarted, its state is effectively lost. However, this allows containers to be packaged into images that can be easily transferred and redeployed on different hosts.</p><hr><h2 id=images-vs-snapshots>Images vs Snapshots<a hidden class=anchor aria-hidden=true href=#images-vs-snapshots>#</a></h2><p>Another key point is the idea of images versus snapshots. Docker uses standardized, declarative images to configure environments, while VMs typically rely on snapshotting. In a VM, the entire system is configured starting from a bare minimum and hopes to preserve the state. The question then becomes: which is faster for app recovery - bootstrapping a VM from a checkpoint on a new machine, or letting a container orchestrator recognize the dead container and restart it elsewhere? Even if they were tied, the argument is that VM checkpoints preserve the state, but the latency cost is high. Docker&rsquo;s persistent volumes allow for state preservation in a serialized way, managed through the application&rsquo;s business logic layer.</p><hr><h2 id=do-we-actually-need-full-isolation>Do We Actually Need Full Isolation?<a hidden class=anchor aria-hidden=true href=#do-we-actually-need-full-isolation>#</a></h2><p>Now, the real question is: do we actually need hardware emulation or total isolation? Data centers absolutely need these for hard isolation requirements and to emulate a variety of hardware configurations. But for most developers, &ldquo;secure enough&rdquo; isolation within a homogeneous stack is sufficient. The largest system I&rsquo;ve seen had 250 images, which could translate into roughly 3000 containers. Given that an average server has fewer than 50 cores, this would require about 60 machines, which is easily achievable with hyperscale providers like AWS hosting hundreds of thousands of servers in one datacenter.</p><p>So, my point is: they&rsquo;re two different tools. Modern containers, with advances in orchestration and performance, cover most use cases. For example, I&rsquo;ve seen containers boot up in a Kubernetes cluster in under 30ms. VMs, however, are about ensuring compatibility with legacy systems. Whether you need to run Apple1-focused software or Nintendo games, VMs give you the ability to do that while maintaining the state - something crucial probably for some scientific computations.</p><p>There&rsquo;s also a middle ground between these two extremes, like KVM, which allows for VM-like workloads to run inside containers. Managing all of these depending on needs is the future. As documented in <a href=https://www.allthingsdistributed.com/2020/09/reinventing-virtualization-with-nitro.html>AWS&rsquo;s migration history</a>, AWS used <a href=https://perspectives.mvdirona.com/2021/11/xen-on-nitro-aws-nitro-for-legacy-instances/>Xen</a> for most of the time, then migrated to proprietary <a href=https://www.allthingsdistributed.com/2020/09/reinventing-virtualization-with-nitro.html>AWS Nitro</a> and now even running some nodes on <a href=https://aws.amazon.com/blogs/aws/firecracker-lightweight-virtualization-for-serverless-computing/>Firecracker microVM</a> which seems to be built on KVM - all of which were mostly probably used as a base layer to host docker images which itself does run a lightweight VM whenever there is a host mismatch.</p><hr><h2 id=closing-thoughts>Closing Thoughts<a hidden class=anchor aria-hidden=true href=#closing-thoughts>#</a></h2><p>Having said all of that - the real tradeoff here is between latency (containers are fast) and availability (as heavy VMs can easily checkpoint and migrate) but mostly these 2 techniques will be stacked on each other in practice and it is worth understanding both. The future isn&rsquo;t about choosing one or the other - it&rsquo;s about knowing when to use which tool, and increasingly, how to use them together in hybrid architectures that give us the best of both worlds.</p><hr></div><footer class=post-footer><ul class=post-tags><li><a href=http://localhost:1313/tags/notes/>Notes</a></li><li><a href=http://localhost:1313/tags/virtualization/>Virtualization</a></li><li><a href=http://localhost:1313/tags/containers/>Containers</a></li><li><a href=http://localhost:1313/tags/docker/>Docker</a></li><li><a href=http://localhost:1313/tags/distributed-systems/>Distributed-Systems</a></li><li><a href=http://localhost:1313/tags/kubernetes/>Kubernetes</a></li></ul><nav class=paginav><a class=prev href=http://localhost:1313/posts/gpu-tvm-triton/><span class=title>« Prev</span><br><span>NOTES: GPU Architecture, TVM, and Triton</span>
</a><a class=next href=http://localhost:1313/posts/tensering-my-torch/><span class=title>Next »</span><br><span>NOTES: TensorFlow, TorchDynamo, and TorchInductor</span></a></nav></footer></article></main><footer class=footer><span>&copy; 2025 <a href=http://localhost:1313/>T|A</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>