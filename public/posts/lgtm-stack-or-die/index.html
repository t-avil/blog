<!doctype html><html lang=en dir=auto><head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>NOTES: Lgtm Stack or Die | T|A</title><meta name=keywords content="notes,observability,grafana,mimir,loki,tempo,phlare,opentelemetry,prometheus,golang,datadog-migration"><meta name=description content="Alloy, Mimir, Loki, Tempo, Phlare, S3, and a lot of hair-pulling"><meta name=author content="Me"><link rel=canonical href=https://canonical.url/to/page><link crossorigin=anonymous href=/assets/css/stylesheet.3f7ba6a00d316a1658af1e52b60f5592bfd3f63e1683217d447958625c9fec2a.css integrity="sha256-P3umoA0xahZYrx5Stg9Vkr/T9j4WgyF9RHlYYlyf7Co=" rel="preload stylesheet" as=style><link rel=icon href=http://localhost:1313/favicon.ico><link rel=icon type=image/png sizes=16x16 href=http://localhost:1313/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=http://localhost:1313/favicon-32x32.png><link rel=apple-touch-icon href=http://localhost:1313/apple-touch-icon.png><link rel=mask-icon href=http://localhost:1313/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=http://localhost:1313/posts/lgtm-stack-or-die/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:url" content="http://localhost:1313/posts/lgtm-stack-or-die/"><meta property="og:site_name" content="T|A"><meta property="og:title" content="NOTES: Lgtm Stack or Die"><meta property="og:description" content="Alloy, Mimir, Loki, Tempo, Phlare, S3, and a lot of hair-pulling"><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-01-13T08:15:04-03:00"><meta property="article:modified_time" content="2025-01-13T08:15:04-03:00"><meta property="article:tag" content="Notes"><meta property="article:tag" content="Observability"><meta property="article:tag" content="Grafana"><meta property="article:tag" content="Mimir"><meta property="article:tag" content="Loki"><meta property="article:tag" content="Tempo"><meta property="og:image" content="http://localhost:1313/images/papermod-cover.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="http://localhost:1313/images/papermod-cover.png"><meta name=twitter:title content="NOTES: Lgtm Stack or Die"><meta name=twitter:description content="Alloy, Mimir, Loki, Tempo, Phlare, S3, and a lot of hair-pulling"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"http://localhost:1313/posts/"},{"@type":"ListItem","position":2,"name":"NOTES: Lgtm Stack or Die","item":"http://localhost:1313/posts/lgtm-stack-or-die/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"NOTES: Lgtm Stack or Die","name":"NOTES: Lgtm Stack or Die","description":"Alloy, Mimir, Loki, Tempo, Phlare, S3, and a lot of hair-pulling","keywords":["notes","observability","grafana","mimir","loki","tempo","phlare","opentelemetry","prometheus","golang","datadog-migration"],"articleBody":" I learned that migrating off a SaaS like Datadog is less a single migration task and more a personality transplant for your infra team. You’re trading a polished one-click thing for a constellation of components that each have opinions, needs, and a flair for dramatic failure modes. But if you survive the awkward first semester, you end up with vendor-neutral observability, much cheaper S3 storage bills, and dashboards you actually control.\nThis is the continuous thread of how that migration goes and what I wish someone had told me before I began wrestling with buckets, rings, and ingestion gateways.\nThe components (the cast) If you replace Datadog with the Grafana open-source stack, the minimal cast looks like this:\nGrafana Alloy - the unified OpenTelemetry ingestion gateway. Everything (metrics, logs, traces, profiles) can flow into Alloy which then routes to the right backend. Think of it as the friendly receptionist of your observability office. Mimir - Prometheus-compatible metrics store and scraper. Stores TSDB blocks in S3 (cold storage) but keeps some local state and needs a cluster of replicas. Uses Cortex-style ring/consensus to coordinate ingesters and queriers. Partially stateful. Loki - logs backend; designed to be effectively stateless when backed by object storage. Push logs via Fluent Bit or an OpenTelemetry Collector; Loki writes to S3 for long-term storage. Tempo - distributed traces; stateless with S3-backed storage so you can scale by adding more replicas. Grafana Phlare - continuous profiler; runs ingesters/queriers/store-gateways and persists to S3. Can also be fed by Pyroscope agents that convert to OTLP. S3-compatible object storage - the cornerstone for cold/durable storage (cheap, durable, and enables stateless operation for Loki/Tempo/Phlare/Mimir TSDB blocks). How Go apps fit in (the developer side) If you write Go microservices, the wiring is straightforward but worth doing right:\nMetrics: instrument with prometheus/client_golang and expose /metrics. Mimir scrapes Prometheus endpoints (it’s Prometheus-compatible). Logs: push via Fluent Bit or the OpenTelemetry Collector to Alloy, which routes to Loki. Don’t ship raw logs directly to S3 - use the pipeline for structure and redaction. Traces: instrument with the OpenTelemetry Go SDK (go.opentelemetry.io/otel) and push spans to Alloy; Alloy forwards to Tempo. Profiling: deploy Grafana Phlare agents or use Pyroscope with an OTLP converter and push profiles through Alloy to Phlare. Tiny example - Prometheus counter in Go (pseudo):\nvar reqs = prometheus.NewCounter(prometheus.CounterOpts{ Name: \"http_requests_total\", Help: \"Total HTTP requests\", }) http.Handle(\"/metrics\", promhttp.Handler()) And initializing OpenTelemetry spans (very high level):\ntp := otel.TracerProvider(/* exporter config that points to Alloy */) otel.SetTracerProvider(tp) tracer := otel.Tracer(\"my-service\") ctx, span := tracer.Start(ctx, \"handleRequest\") defer span.End() Scaling and state: who’s stateful, who pretends not to be Mimir is partially stateful. It writes TSDB blocks to S3, but it also keeps local state and uses a ring/consensus model (Cortex-style) to coordinate ingesters/queriers. You need multiple replicas and to understand the ring behavior. There is no single master, but you can’t treat it like a totally stateless service. Loki and Tempo are effectively stateless when configured with object storage - add replicas behind a load balancer and scale horizontally. Phlare scales horizontally with ingesters, queriers, and store gateways, all backed by S3. Alloy should be deployed with multiple replicas behind a load balancer - it’s the single unified entry point and a potential bottleneck/RPO if under-provisioned. Replication guidance: a deployment with 1-3 replicas per service usually supports moderate volumes (more on data estimates below), assuming proper CPU/memory/network sizing.\nStorage \u0026 cost rough math (two-year window, a real-world-ish estimate) For a moderately noisy legacy Rails app plus ~10 Golang microservices, expect wildly variable numbers depending on verbosity and sampling:\nLogs: ~50-200 GB/day ⇒ ~36-146 TB on S3 over two years. (Logs dominate storage unless you aggressively sample/retention them.) Metrics: with Mimir scraping hundreds of endpoints every 15-30s ⇒ ~1-3 TB/year of compressed TSDB blocks. Traces: sampling-dependent. Medium load might be 100-500 GB/month ⇒ ~2-12 TB over two years. Profiling: tens to hundreds of GB/year depending on sampling frequency and retention. These are not exact; they’re planning numbers. Adjust retention, sampling, and aggregation to control cost.\nOperational advice \u0026 gotchas Use S3-compatible object storage for cheap cold storage and to enable stateless operation for most components. It makes horizontal scaling simple. Automate ingestion and redaction at Alloy/collector level - don’t rely on developers to scrub logs manually. Backups \u0026 verification - Mimir stores TSDB blocks in S3 but requires local state; verify restores/test queries regularly. Ring architecture awareness - Mimir’s ring and ingesters need proper configuration; small misconfig can lead to “where did my time series go?” panics. Replica sizing - Loki/Tempo benefit from many small stateless replicas; Mimir needs thoughtful replica counts and resource planning. Alloy HA - run multiple Alloy replicas so a single node failure doesn’t stop ingestion. The migration payoff \u0026 why I’d do it again Moving off Datadog gave us vendor neutrality (no vendor lock), big S3 cost wins, and full control over data pipelines. We also gained the ability to debug with local copies of data and to iterate on retention policies without calling sales. The tradeoff: more operational work, more components to monitor, and the occasional late-night spelunking into ring metadata.\nPolling vs pushing (the practical verdict) In general: polling (Mimir scraping Prometheus endpoints) provides better reliability and operational simplicity for long-running services. Pushing (client or agent pushes metrics/logs/traces) is reserved for edge cases - short-lived, fire-and-die jobs must push before they die. If a job can crash mid-push, you want a push path; otherwise prefer scrape/polling.\nFinal (slightly sentimental) note This stack is not magic - it’s a set of well-engineered pieces that work together if you invest in configuration, S3, and sane defaults (retention, sampling, RBAC). The migration is equal parts plumbing and patience: there will be nights of head-scratching; there will also be mornings when you realize your monthly bills dropped and you can finally afford snacks for standups. That is the small, beautiful victory of running your own observability.\n","wordCount":"984","inLanguage":"en","image":"http://localhost:1313/images/papermod-cover.png","datePublished":"2025-01-13T08:15:04-03:00","dateModified":"2025-01-13T08:15:04-03:00","author":{"@type":"Person","name":"Me"},"mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:1313/posts/lgtm-stack-or-die/"},"publisher":{"@type":"Organization","name":"T|A","logo":{"@type":"ImageObject","url":"http://localhost:1313/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=http://localhost:1313/ accesskey=h title="T|A (Alt + H)">T|A</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=http://localhost:1313/about title=About><span>About</span></a></li><li><a href=http://localhost:1313/chronicles title=Chronicles><span>Chronicles</span></a></li><li><a href=http://localhost:1313/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=http://localhost:1313/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://github.com/t-avil title=Github><span>Github</span>&nbsp;
<svg fill="none" shape-rendering="geometricPrecision" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=http://localhost:1313/>Home</a>&nbsp;»&nbsp;<a href=http://localhost:1313/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">NOTES: Lgtm Stack or Die</h1><div class=post-description>Alloy, Mimir, Loki, Tempo, Phlare, S3, and a lot of hair-pulling</div><div class=post-meta><span title='2025-01-13 08:15:04 -0300 -0300'>January 13, 2025</span>&nbsp;·&nbsp;5 min&nbsp;·&nbsp;984 words&nbsp;·&nbsp;Me&nbsp;|&nbsp;<a href=https://github.com/t-avil/blog/tree/main/content/posts/lgtm-stack-or-die.md rel="noopener noreferrer edit" target=_blank>Suggest Changes</a></div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><nav id=TableOfContents><ul><li><a href=#the-components-the-cast>The components (the cast)</a></li><li><a href=#how-go-apps-fit-in-the-developer-side>How Go apps fit in (the developer side)</a></li><li><a href=#scaling-and-state-whos-stateful-who-pretends-not-to-be>Scaling and state: who’s stateful, who pretends not to be</a></li><li><a href=#storage--cost-rough-math-two-year-window-a-real-world-ish-estimate>Storage & cost rough math (two-year window, a real-world-ish estimate)</a></li><li><a href=#operational-advice--gotchas>Operational advice & gotchas</a></li><li><a href=#the-migration-payoff--why-id-do-it-again>The migration payoff & why I’d do it again</a></li><li><a href=#polling-vs-pushing-the-practical-verdict>Polling vs pushing (the practical verdict)</a></li><li><a href=#final-slightly-sentimental-note>Final (slightly sentimental) note</a></li></ul></nav></div></details></div><div class=post-content><hr><p>I learned that migrating off a SaaS like Datadog is less a single migration task and more a personality transplant for your infra team. You’re trading a polished one-click thing for a constellation of components that each have opinions, needs, and a flair for dramatic failure modes. But if you survive the awkward first semester, you end up with vendor-neutral observability, much cheaper S3 storage bills, and dashboards you actually control.</p><p>This is the continuous thread of how that migration goes and what I wish someone had told me before I began wrestling with buckets, rings, and ingestion gateways.</p><hr><h2 id=the-components-the-cast>The components (the cast)<a hidden class=anchor aria-hidden=true href=#the-components-the-cast>#</a></h2><p>If you replace Datadog with the Grafana open-source stack, the minimal cast looks like this:</p><ul><li><strong>Grafana Alloy</strong> - the unified OpenTelemetry ingestion gateway. Everything (metrics, logs, traces, profiles) can flow into Alloy which then routes to the right backend. Think of it as the friendly receptionist of your observability office.</li><li><strong>Mimir</strong> - Prometheus-compatible metrics store and scraper. Stores TSDB blocks in S3 (cold storage) but keeps some local state and needs a cluster of replicas. Uses Cortex-style ring/consensus to coordinate ingesters and queriers. Partially stateful.</li><li><strong>Loki</strong> - logs backend; designed to be effectively stateless when backed by object storage. Push logs via Fluent Bit or an OpenTelemetry Collector; Loki writes to S3 for long-term storage.</li><li><strong>Tempo</strong> - distributed traces; stateless with S3-backed storage so you can scale by adding more replicas.</li><li><strong>Grafana Phlare</strong> - continuous profiler; runs ingesters/queriers/store-gateways and persists to S3. Can also be fed by Pyroscope agents that convert to OTLP.</li><li><strong>S3-compatible object storage</strong> - the cornerstone for cold/durable storage (cheap, durable, and enables stateless operation for Loki/Tempo/Phlare/Mimir TSDB blocks).</li></ul><hr><h2 id=how-go-apps-fit-in-the-developer-side>How Go apps fit in (the developer side)<a hidden class=anchor aria-hidden=true href=#how-go-apps-fit-in-the-developer-side>#</a></h2><p>If you write Go microservices, the wiring is straightforward but worth doing right:</p><ul><li><strong>Metrics</strong>: instrument with <code>prometheus/client_golang</code> and expose <code>/metrics</code>. Mimir scrapes Prometheus endpoints (it’s Prometheus-compatible).</li><li><strong>Logs</strong>: push via <strong>Fluent Bit</strong> or the <strong>OpenTelemetry Collector</strong> to Alloy, which routes to Loki. Don’t ship raw logs directly to S3 - use the pipeline for structure and redaction.</li><li><strong>Traces</strong>: instrument with the <strong>OpenTelemetry Go SDK</strong> (<code>go.opentelemetry.io/otel</code>) and push spans to Alloy; Alloy forwards to Tempo.</li><li><strong>Profiling</strong>: deploy <strong>Grafana Phlare agents</strong> or use <strong>Pyroscope</strong> with an OTLP converter and push profiles through Alloy to Phlare.</li></ul><p>Tiny example - Prometheus counter in Go (pseudo):</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-go data-lang=go><span class=line><span class=cl><span class=kd>var</span> <span class=nx>reqs</span> <span class=p>=</span> <span class=nx>prometheus</span><span class=p>.</span><span class=nf>NewCounter</span><span class=p>(</span><span class=nx>prometheus</span><span class=p>.</span><span class=nx>CounterOpts</span><span class=p>{</span>
</span></span><span class=line><span class=cl>  <span class=nx>Name</span><span class=p>:</span> <span class=s>&#34;http_requests_total&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=nx>Help</span><span class=p>:</span> <span class=s>&#34;Total HTTP requests&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl><span class=p>})</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nx>http</span><span class=p>.</span><span class=nf>Handle</span><span class=p>(</span><span class=s>&#34;/metrics&#34;</span><span class=p>,</span> <span class=nx>promhttp</span><span class=p>.</span><span class=nf>Handler</span><span class=p>())</span>
</span></span></code></pre></div><p>And initializing OpenTelemetry spans (very high level):</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-go data-lang=go><span class=line><span class=cl><span class=nx>tp</span> <span class=o>:=</span> <span class=nx>otel</span><span class=p>.</span><span class=nf>TracerProvider</span><span class=p>(</span><span class=cm>/* exporter config that points to Alloy */</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nx>otel</span><span class=p>.</span><span class=nf>SetTracerProvider</span><span class=p>(</span><span class=nx>tp</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nx>tracer</span> <span class=o>:=</span> <span class=nx>otel</span><span class=p>.</span><span class=nf>Tracer</span><span class=p>(</span><span class=s>&#34;my-service&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nx>ctx</span><span class=p>,</span> <span class=nx>span</span> <span class=o>:=</span> <span class=nx>tracer</span><span class=p>.</span><span class=nf>Start</span><span class=p>(</span><span class=nx>ctx</span><span class=p>,</span> <span class=s>&#34;handleRequest&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=k>defer</span> <span class=nx>span</span><span class=p>.</span><span class=nf>End</span><span class=p>()</span>
</span></span></code></pre></div><hr><h2 id=scaling-and-state-whos-stateful-who-pretends-not-to-be>Scaling and state: who’s stateful, who pretends not to be<a hidden class=anchor aria-hidden=true href=#scaling-and-state-whos-stateful-who-pretends-not-to-be>#</a></h2><ul><li><strong>Mimir</strong> is <em>partially stateful</em>. It writes TSDB blocks to S3, but it also keeps local state and uses a ring/consensus model (Cortex-style) to coordinate ingesters/queriers. You need multiple replicas and to understand the ring behavior. There is no single master, but you can&rsquo;t treat it like a totally stateless service.</li><li><strong>Loki</strong> and <strong>Tempo</strong> are effectively <em>stateless</em> when configured with object storage - add replicas behind a load balancer and scale horizontally.</li><li><strong>Phlare</strong> scales horizontally with ingesters, queriers, and store gateways, all backed by S3.</li><li><strong>Alloy</strong> should be deployed with multiple replicas behind a load balancer - it’s the single unified entry point and a potential bottleneck/RPO if under-provisioned.</li></ul><p>Replication guidance: a deployment with <strong>1-3 replicas per service</strong> usually supports moderate volumes (more on data estimates below), assuming proper CPU/memory/network sizing.</p><hr><h2 id=storage--cost-rough-math-two-year-window-a-real-world-ish-estimate>Storage & cost rough math (two-year window, a real-world-ish estimate)<a hidden class=anchor aria-hidden=true href=#storage--cost-rough-math-two-year-window-a-real-world-ish-estimate>#</a></h2><p>For a moderately noisy legacy Rails app plus ~10 Golang microservices, expect wildly variable numbers depending on verbosity and sampling:</p><ul><li><strong>Logs</strong>: ~50-200 GB/day ⇒ <strong>~36-146 TB</strong> on S3 over two years. (Logs dominate storage unless you aggressively sample/retention them.)</li><li><strong>Metrics</strong>: with Mimir scraping hundreds of endpoints every 15-30s ⇒ <strong>~1-3 TB/year</strong> of compressed TSDB blocks.</li><li><strong>Traces</strong>: sampling-dependent. Medium load might be <strong>100-500 GB/month</strong> ⇒ <strong>~2-12 TB</strong> over two years.</li><li><strong>Profiling</strong>: tens to hundreds of GB/year depending on sampling frequency and retention.</li></ul><p>These are not exact; they’re <em>planning</em> numbers. Adjust retention, sampling, and aggregation to control cost.</p><hr><h2 id=operational-advice--gotchas>Operational advice & gotchas<a hidden class=anchor aria-hidden=true href=#operational-advice--gotchas>#</a></h2><ul><li><strong>Use S3-compatible object storage</strong> for cheap cold storage and to enable stateless operation for most components. It makes horizontal scaling simple.</li><li><strong>Automate ingestion and redaction</strong> at Alloy/collector level - don’t rely on developers to scrub logs manually.</li><li><strong>Backups & verification</strong> - Mimir stores TSDB blocks in S3 but requires local state; verify restores/test queries regularly.</li><li><strong>Ring architecture awareness</strong> - Mimir&rsquo;s ring and ingesters need proper configuration; small misconfig can lead to “where did my time series go?” panics.</li><li><strong>Replica sizing</strong> - Loki/Tempo benefit from many small stateless replicas; Mimir needs thoughtful replica counts and resource planning.</li><li><strong>Alloy HA</strong> - run multiple Alloy replicas so a single node failure doesn’t stop ingestion.</li></ul><hr><h2 id=the-migration-payoff--why-id-do-it-again>The migration payoff & why I’d do it again<a hidden class=anchor aria-hidden=true href=#the-migration-payoff--why-id-do-it-again>#</a></h2><p>Moving off Datadog gave us vendor neutrality (no vendor lock), big S3 cost wins, and full control over data pipelines. We also gained the ability to debug with local copies of data and to iterate on retention policies without calling sales. The tradeoff: more operational work, more components to monitor, and the occasional late-night spelunking into ring metadata.</p><hr><h2 id=polling-vs-pushing-the-practical-verdict>Polling vs pushing (the practical verdict)<a hidden class=anchor aria-hidden=true href=#polling-vs-pushing-the-practical-verdict>#</a></h2><p>In general: <strong>polling</strong> (Mimir scraping Prometheus endpoints) provides better reliability and operational simplicity for long-running services. <strong>Pushing</strong> (client or agent pushes metrics/logs/traces) is reserved for edge cases - short-lived, fire-and-die jobs must push before they die. If a job can crash mid-push, you want a push path; otherwise prefer scrape/polling.</p><hr><h2 id=final-slightly-sentimental-note>Final (slightly sentimental) note<a hidden class=anchor aria-hidden=true href=#final-slightly-sentimental-note>#</a></h2><p>This stack is not magic - it’s a set of well-engineered pieces that work together if you invest in configuration, S3, and sane defaults (retention, sampling, RBAC). The migration is equal parts plumbing and patience: there will be nights of head-scratching; there will also be mornings when you realize your monthly bills dropped and you can finally afford snacks for standups. That is the small, beautiful victory of running your own observability.</p></div><footer class=post-footer><ul class=post-tags><li><a href=http://localhost:1313/tags/notes/>Notes</a></li><li><a href=http://localhost:1313/tags/observability/>Observability</a></li><li><a href=http://localhost:1313/tags/grafana/>Grafana</a></li><li><a href=http://localhost:1313/tags/mimir/>Mimir</a></li><li><a href=http://localhost:1313/tags/loki/>Loki</a></li><li><a href=http://localhost:1313/tags/tempo/>Tempo</a></li><li><a href=http://localhost:1313/tags/phlare/>Phlare</a></li><li><a href=http://localhost:1313/tags/opentelemetry/>Opentelemetry</a></li><li><a href=http://localhost:1313/tags/prometheus/>Prometheus</a></li><li><a href=http://localhost:1313/tags/golang/>Golang</a></li><li><a href=http://localhost:1313/tags/datadog-migration/>Datadog-Migration</a></li></ul><nav class=paginav><a class=prev href=http://localhost:1313/posts/mmorpgs-from-be-eng-perspective/><span class=title>« Prev</span><br><span>NOTES: MMORPGs From BE Eng Perspective</span>
</a><a class=next href=http://localhost:1313/posts/end2ending-data-warehouse/><span class=title>Next »</span><br><span>NOTES: End to ending Data Warehouses as a concept</span></a></nav></footer></article></main><footer class=footer><span>&copy; 2025 <a href=http://localhost:1313/>T|A</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>